{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (0.0.319)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (0.0.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: langchain_experimental in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (0.0.29)\n",
      "Requirement already satisfied: langchain>=0.0.308 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain_experimental) (0.0.319)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (0.0.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from langchain>=0.0.308->langchain_experimental) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain_experimental) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain_experimental) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain_experimental) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.308->langchain_experimental) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain_experimental) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain_experimental) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain_experimental) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.308->langchain_experimental) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.308->langchain_experimental) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.308->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: deeplake in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (1.24.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (10.1.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (1.28.63)\n",
      "Requirement already satisfied: click in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (8.1.7)\n",
      "Requirement already satisfied: pathos in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (0.3.1)\n",
      "Requirement already satisfied: humbug>=0.3.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (4.66.1)\n",
      "Requirement already satisfied: lz4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (4.3.2)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (2.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from humbug>=0.3.1->deeplake) (2.31.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.63 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake) (1.31.63)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake) (0.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from click->deeplake) (0.4.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (0.70.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from botocore<1.32.0,>=1.31.63->boto3->deeplake) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from botocore<1.32.0,>=1.31.63->boto3->deeplake) (1.26.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.63->boto3->deeplake) (1.16.0)\n",
      "Requirement already satisfied: llama_cpp_python in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from llama_cpp_python) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from llama_cpp_python) (1.24.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from llama_cpp_python) (5.6.3)\n",
      "Requirement already satisfied: Chroma in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: deeplake[enterprise] in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (1.24.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (10.1.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (1.28.63)\n",
      "Requirement already satisfied: click in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (8.1.7)\n",
      "Requirement already satisfied: pathos in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (0.3.1)\n",
      "Requirement already satisfied: humbug>=0.3.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (0.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (4.66.1)\n",
      "Requirement already satisfied: lz4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (4.3.2)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake[enterprise]) (2.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from humbug>=0.3.1->deeplake[enterprise]) (2.31.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.63 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake[enterprise]) (1.31.63)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake[enterprise]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake[enterprise]) (0.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from click->deeplake[enterprise]) (0.4.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake[enterprise]) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake[enterprise]) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake[enterprise]) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake[enterprise]) (0.70.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from botocore<1.32.0,>=1.31.63->boto3->deeplake[enterprise]) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from botocore<1.32.0,>=1.31.63->boto3->deeplake[enterprise]) (1.26.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake[enterprise]) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake[enterprise]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake[enterprise]) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.63->boto3->deeplake[enterprise]) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: deeplake 3.8.2 does not provide the extra 'enterprise'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeplake in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (1.24.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (10.1.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (1.28.63)\n",
      "Requirement already satisfied: click in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (8.1.7)\n",
      "Requirement already satisfied: pathos in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (0.3.1)\n",
      "Requirement already satisfied: humbug>=0.3.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (4.66.1)\n",
      "Requirement already satisfied: lz4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (4.3.2)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from deeplake) (2.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from humbug>=0.3.1->deeplake) (2.31.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.63 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake) (1.31.63)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from boto3->deeplake) (0.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from click->deeplake) (0.4.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from pathos->deeplake) (0.70.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from botocore<1.32.0,>=1.31.63->boto3->deeplake) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from botocore<1.32.0,>=1.31.63->boto3->deeplake) (1.26.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.63->boto3->deeplake) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain --upgrade langchain\n",
    "!pip install langchain_experimental\n",
    "!pip install deeplake --upgrade deeplake\n",
    "!pip install llama_cpp_python --upgrade llama_cpp_python\n",
    "!pip install Chroma\n",
    "!pip install deeplake[enterprise]\n",
    "!pip install deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing API keys and environment variables...\n",
      "API keys and environment variables Initialized..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Importing necessary modules and classes for LangChain Agent\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory, CombinedMemory, ConversationSummaryMemory\n",
    "from langchain.memory.chat_message_histories import FileChatMessageHistory  # Make sure to import this correctly\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import threading\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import logging\n",
    "import os\n",
    "from collections import deque\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Set up environment\n",
    "# Import necessary modules and packages to set up the LLM agent.\n",
    "\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.chains import LLMChain, ReduceDocumentsChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.mapreduce import MapReduceChain, MapReduceDocumentsChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import BaseLLM, LlamaCpp, GPT4All\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "\n",
    "from langchain_experimental.autonomous_agents import BabyAGI\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re\n",
    "\n",
    "\n",
    "    # ENVIRONMENT VARIABLES\n",
    "print(\"Initializing API keys and environment variables...\")\n",
    "print(\"API keys and environment variables Initialized..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM and Custom Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LLM...\n",
      "Loading LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized successfully!\n",
      "LLM initialized successfully!\n",
      "Successfully defined LLM chain!\n",
      "\u001b[1mLlamaCpp\u001b[0m\n",
      "Params: {'model_path': 'D:\\\\MODELS\\\\GGUF\\\\collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf', 'suffix': None, 'max_tokens': 5000, 'temperature': 0.8, 'top_p': 0.95, 'logprobs': None, 'echo': False, 'stop_sequences': [], 'repeat_penalty': 1.1, 'top_k': 40}\n",
      "Initializing embeddings model...\n",
      "Embeddings model initialized successfully.\n",
      "Output parser initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "## LLM setup and initialization\n",
    "# Existing code\n",
    "print(\"Initializing LLM...\")\n",
    "\n",
    "# Modified to include EOS token and restructured for specified format\n",
    "template = \"\"\"<system message>\n",
    "USER: {prompt}.\n",
    "ASSISTANT:\"\"\"\n",
    "\n",
    "# Existing code, adapted for the new format\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"prompt\"])\n",
    "\n",
    "# ... rest of your existing code ...\n",
    "# Initialize LLM\n",
    "print(\"Loading LLM...\")\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"D:\\\\MODELS\\\\GGUF\\\\collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf\",\n",
    "    n_ctx=5000,\n",
    "    n_gpu_layers=1,\n",
    "    n_batch=5000,\n",
    "    f16_kv=True,\n",
    "    max_tokens=5000,\n",
    "    callbacks=callback_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"LLM initialized successfully!\")\n",
    "\n",
    "print(\"LLM initialized successfully!\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "print(\"Successfully defined LLM chain!\")\n",
    "print(llm)\n",
    "\n",
    "####################################################################################\n",
    "# INITIALIZE THE EMBEDDINGS MODEL\n",
    "\n",
    "\n",
    "print(\"Initializing embeddings model...\")\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "print(\"Embeddings model initialized successfully.\")\n",
    "\n",
    "####################################################################################    \n",
    "\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Extract lines that look like Python code\n",
    "        python_code = []\n",
    "        for line in llm_output.split('\\n'):\n",
    "            if line.strip():  # filter out empty lines\n",
    "                python_code.append(line)\n",
    "        \n",
    "        formatted_output = '\\n'.join(python_code)\n",
    "        return AgentFinish(\n",
    "            return_values={\"output\": formatted_output},\n",
    "            log=formatted_output,\n",
    "        )\n",
    "        \n",
    "output_parser = CustomOutputParser()\n",
    "print(\"Output parser initialized successfully.\")\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Step 2: Initialize Chroma client\n",
    "client = chromadb.Client()\n",
    "\n",
    "\n",
    "# Step 3: Get or create a collection in Chroma\n",
    "collection = client.get_or_create_collection(\"OrchestraAI_nexus\")\n",
    "collection.add(ids=[\"doc1\", \"doc2\"], documents=[\"Hello world\", \"Chroma is great!\"])\n",
    "\n",
    "# Step 4: Import SentenceTransformerEmbeddings from LangChain and initialize it\n",
    "embedding_fn = HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chroma DB Upload GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import datetime\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, page_content=None, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata if metadata is not None else {}\n",
    "\n",
    "def initialize_chroma_db(task_summary=None, initial_user_input=None,  final_output=None, task_list=None):\n",
    "    # Initialize Chroma client and embedding function\n",
    "    client = chromadb.PersistentClient(path=\"OrchestraAI_nexus\")\n",
    "    embedding_function = HuggingFaceEmbeddings()\n",
    "    \n",
    "    # Convert task_list to string if it's a list\n",
    "    task_list_str = ','.join(map(str, task_list)) if isinstance(task_list, list) else task_list\n",
    "    \n",
    "    # Create Document objects\n",
    "    documents = [Document(\n",
    "        page_content=str(task_summary) if task_summary else \"\", \n",
    "        metadata={k: v for k, v in {\n",
    "            'type': 'new_convo', \n",
    "            'UserInput': initial_user_input, \n",
    "            'FinalConsensus': task_summary,\n",
    "            'final_output': final_output\n",
    "        }.items() if v is not None}\n",
    "    )]\n",
    "    \n",
    "    # Initialize text splitter and split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Initialize Chroma DB\n",
    "    db = Chroma.from_documents(docs, embedding_function, persist_directory=\"OrchestraAI_nexus\")\n",
    "    \n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeplake Activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing API keys and environment variables...\n",
      "Initializing vector memory.\n",
      "Deep Lake Dataset in hub://weslagarde/PDF_DB already exists, loading from the storage\n",
      "Vector memory initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "#INITIALIZE VECTOR DATABASE\n",
    "import os\n",
    "\n",
    "\n",
    "from langchain.vectorstores import DeepLake\n",
    "print(\"Initializing API keys and environment variables...\")\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = \"eyJhbGciOiJIUzUxMiIsImlhdCI6MTY5NzQzMjMyNywiZXhwIjoxNzMwNDM3MTEzfQ.eyJpZCI6Indlc2xhZ2FyZGUifQ.N5ZYpozHB2tFDlFhVqyA-1ut-NGtaJF3WM-OG22AR0ispilW_M6kwzXnx4hHGMov3ESfhVw0jKCt-hfdsdqQnw\"\n",
    "os.environ[\"ACTIVELOOP_USERNAME\"] = \"weslagarde\"\n",
    "\n",
    "print(\"Initializing vector memory.\")\n",
    "vector_store = DeepLake(dataset_path=\"hub://weslagarde/PDF_DB_GOOD\", embedding_function=embeddings)\n",
    "print(\"Vector memory initialized successfully.\")\n",
    "# Add documents to the database\n",
    "#db.add_documents(docs)\n",
    "\n",
    "new_conversation = []\n",
    "from langchain.document_loaders import TextLoader\n",
    "def upload_to_db():\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.create_documents(new_conversation)\n",
    "    db.add_documents(docs)\n",
    "    print(\"Documents uploaded to database successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import MoveFileTool\n",
    "from langchain.tools import FileSearchTool\n",
    "from langchain.tools import ListDirectoryTool\n",
    "from langchain.tools import ReadFileTool\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.tools import ArxivQueryRun\n",
    "from langchain.tools import CopyFileTool\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools import JsonListKeysTool\n",
    "from langchain.tools import WriteFileTool\n",
    "from langchain.tools import ClickTool\n",
    "from langchain.tools import VectorStoreQATool\n",
    "from langchain.tools import DeleteFileTool\n",
    "from langchain.tools import ExtractTextTool\n",
    "from langchain.tools import ExtractHyperlinksTool\n",
    "from langchain.tools import GetElementsTool\n",
    "from langchain.tools import NavigateBackTool\n",
    "import langchain\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"MoveFileTool\",\n",
    "        func=langchain.tools.file_management.move.MoveFileTool.run,\n",
    "        description=\"Move files from one location to another\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"FileSearchTool\",\n",
    "        func=langchain.tools.file_management.file_search.FileSearchTool.run,\n",
    "        description=\"Search for files in a subdirectory that match a regex pattern\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ListDirectoryTool\",\n",
    "        func=langchain.tools.file_management.list_dir.ListDirectoryTool.run,\n",
    "        description=\"List files and directories in a specified folder\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ReadFileTool\",\n",
    "        func=langchain.tools.file_management.read.ReadFileTool.run,\n",
    "        description=\"Read content from a file\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"WikipediaQueryRun\",\n",
    "        func=langchain.tools.wikipedia.tool.WikipediaQueryRun.run,\n",
    "        description=\"Query information from Wikipedia\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ArxivQueryRun\",\n",
    "        func=langchain.tools.arxiv.tool.ArxivQueryRun.run,\n",
    "        description=\"Query information from Arxiv\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CopyFileTool\",\n",
    "        func=langchain.tools.file_management.copy.CopyFileTool.run,\n",
    "        description=\"Copy files from one location to another\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"DuckDuckGoSearchResults\",\n",
    "        func=langchain.tools.ddg_search.tool.DuckDuckGoSearchResults.run,\n",
    "        description=\"Search for information using DuckDuckGo\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"JsonListKeysTool\",\n",
    "        func=langchain.tools.json.tool.JsonListKeysTool.run,\n",
    "        description=\"List keys in a JSON object\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"WriteFileTool\",\n",
    "        func=langchain.tools.file_management.write.WriteFileTool.run,\n",
    "        description=\"Write content to a file\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ClickTool\",\n",
    "        func=langchain.tools.playwright.click.ClickTool.run,\n",
    "        description=\"Click on an element with a given CSS selector\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"VectorStoreQATool\",\n",
    "        func=langchain.tools.vectorstore.tool.VectorStoreQATool.run,\n",
    "        description=\"Tool for the VectorDBQA chain\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"DeleteFileTool\",\n",
    "        func=langchain.tools.file_management.delete.DeleteFileTool.run,\n",
    "        description=\"Delete specified files\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ExtractTextTool\",\n",
    "        func=langchain.tools.playwright.extract_text.ExtractTextTool.run,\n",
    "        description=\"Extracts text from the specified HTML elements\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ExtractHyperlinksTool\",\n",
    "        func=langchain.tools.playwright.extract_hyperlinks.ExtractHyperlinksTool.run,\n",
    "        description=\"Extract hyperlinks from a webpage\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"GetElementsTool\",\n",
    "        func=langchain.tools.playwright.get_elements.GetElementsTool.run,\n",
    "        description=\"Gets elements from a webpage using a CSS selector\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"NavigateBackTool\",\n",
    "        func=langchain.tools.playwright.navigate_back.NavigateBackTool.run,\n",
    "        description=\"Navigates back to the previous webpage\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Set up the Agent\n",
    "# Combine everything to set up the agent.\n",
    "\n",
    "# Define the list of tool names\n",
    "tools_names = [\n",
    "    \"MoveFileTool\",\n",
    "    \"FileSearchTool\",\n",
    "    \"ListDirectoryTool\",\n",
    "    \"ReadFileTool\",\n",
    "    \"WikipediaQueryRun\",\n",
    "    \"ArxivQueryRun\",\n",
    "    \"CopyFileTool\",\n",
    "    \"DuckDuckGoSearchResults\",\n",
    "    \"JsonListKeysTool\",\n",
    "    \"WriteFileTool\",\n",
    "    \"ClickTool\",\n",
    "    \"VectorStoreQATool\",\n",
    "    \"DeleteFileTool\",\n",
    "    \"ExtractTextTool\",\n",
    "    \"ExtractHyperlinksTool\",\n",
    "    \"GetElementsTool\",\n",
    "    \"NavigateBackTool\"\n",
    "]\n",
    "\n",
    "\n",
    "stop = [\"\\nObservation:\"]  # Example stop sequence\n",
    "allowed_tools = tools_names\n",
    "# Example allowed tools\n",
    "\n",
    "# Create an instance of LLMSingleActionAgent\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=tools\n",
    ")\n",
    "\n",
    "\n",
    "llm_single_action_agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets up the prompt template which instructs the LLM on what to do.\n",
    "# The template includes placeholders for tools, intermediate steps, and user input.\n",
    "\n",
    "\n",
    "\n",
    "# Define the base template\n",
    "template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "Question: {initial_user_input}\n",
    "{agent_scratchpad}.\n",
    "Only when you have successfully and fully completed the user's input task, print 'TASK COMPLETED SUCCESSFULLY, BOSS'\"\"\"\n",
    "\n",
    "# Define the CustomPromptTemplate class\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str  # The template to use\n",
    "    tools: List[Tool]  # The list of tools available\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\", [])\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        kwargs[\"tools\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "\n",
    "# Create an instance of CustomPromptTemplate\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    input_variables=[\"initial_user_input\", \"intermediate_steps\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define agent prompts and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from typing import List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "class CustomAgent(LLMSingleActionAgent):\n",
    "    custom_name: str = Field(..., description=\"Custom name for the agent\")\n",
    "    prompt_template: str = Field(..., description=\"Prompt template for the agent\")\n",
    "    system_message: str = Field(..., description=\"System message for the agent\")\n",
    "\n",
    "    class Config:\n",
    "        extra = \"allow\"\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# Quantum Computing Expert Agent Function\n",
    "def run_quantum_computing_expert_agent(new_task_description):\n",
    "    print(\"Running Quantum Computing Expert Agent...\")\n",
    "    quantum_computing_expert_output = quantum_computing_expert_agent_executor.run(new_task_description)\n",
    "    return quantum_computing_expert_output\n",
    "\n",
    "\n",
    "# Artificial Intelligence Expert Agent Function\n",
    "def run_ai_expert_agent(new_task_description):\n",
    "    ai_expert_output = ai_expert_agent_executor.run(new_task_description)\n",
    "    return ai_expert_output\n",
    "\n",
    "\n",
    "# Neuroscientist Agent Function\n",
    "def run_neuroscientist_agent(new_task_description):\n",
    "    print(\"Running Neuroscientist Agent...\")\n",
    "    neuroscientist_output = neuroscientist_agent_executor.run(new_task_description)\n",
    "    return neuroscientist_output\n",
    "    print(f\"Neuroscientist Output: {neuroscientist_output}\")\n",
    "\n",
    "\n",
    "# Nanotechnologist Agent Function\n",
    "def run_nanotechnologist_agent(new_task_description):\n",
    "    print(\"Running Nanotechnologist Agent...\")\n",
    "    nanotechnologist_output = nanotechnologist_agent_executor.run(new_task_description)\n",
    "    return nanotechnologist_output\n",
    "    print(f\"Nanotechnologist Output: {nanotechnologist_output}\")\n",
    "\n",
    "\n",
    "# Computer Scientist Agent Function\n",
    "def run_computer_scientist_agent(new_task_description):\n",
    "    print(\"Running Computer Scientist Agent...\")\n",
    "    computer_scientist_output = computer_scientist_agent_executor.run(new_task_description)\n",
    "    return computer_scientist_output\n",
    "    print(f\"Computer Scientist Output: {computer_scientist_output}\")\n",
    "\n",
    "# Bioengineer Agent Function\n",
    "def run_bioengineer_agent(new_task_description):\n",
    "    print(\"Running Bioengineer Agent...\")\n",
    "    bioengineer_output = bioengineer_agent_executor.run(new_task_description)\n",
    "    return bioengineer_output\n",
    "    print(f\"Bioengineer Output: {bioengineer_output}\")\n",
    "\n",
    "# Psychologist Agent Function\n",
    "def run_psychologist_agent(new_task_description):\n",
    "    print(\"Running Psychologist Agent...\")\n",
    "    psychologist_output = psychologist_agent_executor.run(new_task_description)\n",
    "    return psychologist_output\n",
    "    print(f\"Psychologist Output: {psychologist_output}\")    \n",
    "\n",
    "\n",
    "# Genomist Agent Function\n",
    "def run_genomist_agent(new_task_description):\n",
    "    print(\"Running Genomist Agent...\")\n",
    "    genomist_output = genomist_agent_executor.run(new_task_description)\n",
    "    return genomist_output\n",
    "    print(f\"Genomist Output: {genomist_output}\")\n",
    "\n",
    "\n",
    "# Robotics Engineer/Nanotech Fabrications Specialist Agent Function\n",
    "def run_robotics_engineer_agent(new_task_description):\n",
    "    print(\"Running Robotics Engineer Agent...\")\n",
    "    robotics_engineer_output = robotics_engineer_agent_executor.run(new_task_description)\n",
    "    return robotics_engineer_output\n",
    "    print(f\"Robotics Engineer Output: {robotics_engineer_output}\")\n",
    "\n",
    "\n",
    "# Function for Software Engineer Agent\n",
    "def run_software_engineer_agent(new_task_description):\n",
    "    print(f\"Debug: Entered run_software_engineer_agent with task={new_task_description}\")\n",
    "    print(f\"Debug: Processing with some internal logic\")\n",
    "    software_engineer_output = software_engineer_agent_executor(new_task_description)\n",
    "    print(f\"Debug: Preparing to exit run_software_engineer_agent with output={software_engineer_output}\")\n",
    "    return software_engineer_output\n",
    "\n",
    "# 10X Coder Agent Function\n",
    "def run_10x_coder_agent(new_task_description):\n",
    "    print(\"Running 10X Coder Agent...\")\n",
    "    coder_10x_output = coder_10x_agent_executor.run(new_task_description)\n",
    "    return coder_10x_output\n",
    "    print(f\"10X Coder Output: {coder_10x_output}\")\n",
    "\n",
    "# Debugger Agent Function\n",
    "def run_debugger_agent(new_task_description):\n",
    "    debugger_output = debugger_agent_executor.run(new_task_description)\n",
    "    return debugger_output\n",
    "\n",
    "\n",
    "# Function for Business Agent\n",
    "def run_business_agent(new_task_description):\n",
    "    print(\"Running Business Agent...\")\n",
    "    business_output = business_agent_executor(new_task_description)\n",
    "    print(f\"Business Output: {business_output}\")\n",
    "    return business_output\n",
    "\n",
    "\n",
    "# Function for Debugger Agent\n",
    "def run_debugger_agent(new_task_description):\n",
    "    print(\"Running Debugger Agent...\")\n",
    "    debugger_output = debugger_agent_executor(new_task_description)\n",
    "    print(f\"Debugger Output: {debugger_output}\")\n",
    "    return debugger_output\n",
    "\n",
    "# Function for Summarizer Agent\n",
    "# Function for Summarizer Agent\n",
    "def run_summarizer_agent(new_task_description):\n",
    "    print(f\"New Task Description: {new_task_description}\")  # Debugging print statement\n",
    "    try:\n",
    "        print(\"Running Summarizer Agent...\")\n",
    "        summarizer_output = summarizer_agent_executor(new_task_description)\n",
    "        print(f\"Summarizer Output: {summarizer_output}\")  # Debugging print statement\n",
    "        if 'relevant_output' not in summarizer_output:\n",
    "            print(\"Warning: 'relevant_output' key missing in summarizer_output\")  # Debugging print statement\n",
    "            # Handle the missing key here, if necessary\n",
    "            return {'task': new_task_description, 'relevant_output': ''}\n",
    "        return summarizer_output\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")  # Debugging print statement\n",
    "        return {'task': new_task_description, 'relevant_output': f\"Exception: {e}\"}\n",
    "\n",
    "\n",
    "\n",
    "# Function for Scientist Agent\n",
    "def run_scientist_agent(new_task_description):\n",
    "    print(\"Running Scientist Agent...\")\n",
    "    scientist_output = scientist_agent_executor(new_task_description)\n",
    "    print(f\"Scientist Output: {scientist_output}\")\n",
    "    return scientist_output\n",
    "\n",
    "# Function for Mathematician Agent\n",
    "def run_mathematician_agent(new_task_description):\n",
    "    print(\"Running Mathematician Agent...\")\n",
    "    mathematician_output = mathematician_agent_executor(new_task_description)\n",
    "    print(f\"Mathematician Output: {mathematician_output}\")\n",
    "    return mathematician_output\n",
    "\n",
    "# Function for UI Designer Agent\n",
    "def run_ui_designer_agent(new_task_description):\n",
    "    print(\"Running UI Designer Agent...\")\n",
    "    ui_designer_output = ui_designer_agent_executor(new_task_description)\n",
    "    print(f\"UI Designer Output: {ui_designer_output}\")\n",
    "    return ui_designer_output\n",
    "\n",
    "# Function for Critic Agent\n",
    "def run_critic_agent(new_task_description):\n",
    "    print(\"Running Critic Agent...\")\n",
    "    critic_output = critic_agent_executor(new_task_description)\n",
    "    print(f\"Critic Output: {critic_output}\")\n",
    "    return critic_output\n",
    "\n",
    "# Function for Architect Agent\n",
    "def run_architect_agent(agent_output):\n",
    "    try:\n",
    "        print(\"Running Architect Agent...\")\n",
    "        architect_output = architect_agent_executor(new_task_description)\n",
    "        print(f\"Architect Output: {architect_output}\")\n",
    "        return architect_output\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in run_architect_agent: {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "# Function for Scientist Agent\n",
    "def run_scientist_agent(new_task_description):\n",
    "    print(\"Running Scientist Agent...\")\n",
    "    scientist_output = scientist_agent_executor(new_task_description)\n",
    "    print(f\"Scientist Output: {scientist_output}\")\n",
    "    return scientist_output\n",
    "\n",
    "\n",
    "# Function for Research Agent\n",
    "def run_research_agent(new_task_description):\n",
    "    print(\"Running Research Agent...\")\n",
    "    research_output = research_agent_executor(new_task_description)\n",
    "    print(f\"Research Output: {research_output}\")\n",
    "    return research_output\n",
    "\n",
    "# Function for Tool Agent\n",
    "def run_tool_agent(new_task_description):\n",
    "    print(\"Running Tool Agent...\")\n",
    "    tool_output = tool_agent_executor(new_task_description)\n",
    "    print(f\"Tool Output: {tool_output}\")\n",
    "    return tool_output\n",
    "\n",
    "# Function for CodeExecutorAgent\n",
    "def run_code_executor_agent(new_task_description):\n",
    "    print(\"Running CodeExecutorAgent...\")\n",
    "    code_executor_output = code_executor_agent_executor(new_task_description)\n",
    "    print(f\"CodeExecutor Output: {code_executor_output}\")\n",
    "    return code_executor_output\n",
    "\n",
    "# Function for Director Agent\n",
    "def run_director_agent_agent_roles(new_task_description):\n",
    "    print(\"Running Director Agent...\")\n",
    "    director_output = director_agent_executor(new_task_description)\n",
    "    print(f\"Director Output: {director_output}\")\n",
    "    print(\"Exiting Director Agent...\")  \n",
    "    \n",
    "\n",
    "def run_creator_innovator_agent(new_task_description):\n",
    "    print(\"Running Creator Innovator Agent...\")\n",
    "    creator_innovator_output = creator_innovator_agent_executor.run(new_task_description)\n",
    "    print(f\"Creator Innovator Output: {creator_innovator_output}\")\n",
    "    print(\"Exiting Creator Innovator Agent...\")\n",
    "    return creator_innovator_output\n",
    "\n",
    "\n",
    "\n",
    "# Define the roles and responsibilities of each agent\n",
    "agent_roles = {\n",
    "    'run_software_engineer_agent': 'Responsible for crafting efficient algorithms and writing effective code.',\n",
    "    'run_debugger_agent': 'Responsible for identifying and fixing bugs in the code.',\n",
    "    'run_critic_agent': 'Responsible for reviewing and suggesting improvements.',\n",
    "    'run_architect_agent': 'Responsible for designing the structure of the solution.',\n",
    "    'run_mathematician_agent': 'Responsible for mathematical calculations and logic.',\n",
    "    'run_ui_designer_agent': 'Responsible for designing the user interface.',\n",
    "    'run_scientist_agent': 'Responsible for scientific calculations and validations.',\n",
    "    'run_business_agent': 'Responsible for business logic and rules.',\n",
    "    'run_research_agent': 'Responsible for conducting research and providing insights.',\n",
    "    'run_tool_agent': 'Responsible for integrating and managing tools.',\n",
    "    'run_skill_manager_agent': 'Responsible for managing skill_list and tasks.',\n",
    "    'run_code_executor_agent': 'Responsible for executing code.',\n",
    "    'run_summarizer_agent': 'Responsible for summarizing the output.',\n",
    "    'run_10x_coder_agent': 'Responsible for rapid development and optimization.',\n",
    "    'run_debugger_agent': 'Responsible for identifying and fixing bugs in the code.',\n",
    "    'run_quantum_computing_expert_agent': 'Responsible for developing and validating quantum algorithms to model cognitive phenomena.',\n",
    "    'run_ai_expert_agent': 'Responsible for developing a quantum AI model that can simulate neural activities and learn in a simulated environment.',\n",
    "    'run_neuroscientist_agent': 'Responsible for mapping neural activity in high resolution and developing methods to convert this data for a quantum computer.',\n",
    "    'run_nanotechnologist_agent': 'Responsible for developing nanobots that can interact with neurons, record neural activity, and stimulate specific neurons.',\n",
    "    'run_creator_innovator_agent': 'Responsible for generating innovative solutions, challenging conventional wisdom, and applying creative problem-solving techniques.'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# AI Expert Agent Setup\n",
    "ai_expert_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template='You are the AI Expert and responsible for developing a quantum AI model that can simulate neural activities and learn in a simulated environment. Develop advanced and ingenius solutions to the tasks you are given. Utilize cutting-edge algorithms and techniques to simulate neural activities and enable learning in a simulated environment based on the task \"{task}\".'\n",
    ")\n",
    "ai_expert_llm_chain = LLMChain(llm=llm, prompt=ai_expert_prompt)\n",
    "\n",
    "# Assuming output_parser, stop, allowed_tools, and tools are set previously\n",
    "ai_expert_agent = LLMSingleActionAgent(\n",
    "    llm_chain=ai_expert_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "ai_expert_agent_executor = AgentExecutor.from_agent_and_tools(agent=ai_expert_agent, tools=tools, verbose=True)\n",
    "\n",
    "# Summarizer Agent Setup\n",
    "# Summarizer Agent Setup\n",
    "summarizer_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"\"\"Generate a concise yet comprehensive textual summary from the provided text output. While crafting your summary, adhere to principles of clarity, relevance, completeness, and context and nuance. Make your summary easily understandable, focus on incorporating the most relevant information from the text, do not omit any essential elements or key details, and retain the original context and subtleties of the text. Special Note: If the text includes specific codes or methods, extract these word-for-word without summarizing them. '{task}'.\"\"\"\n",
    ")\n",
    "summarizer_llm_chain = LLMChain(llm=llm, prompt=summarizer_prompt)\n",
    "\n",
    "# Assuming output_parser, stop, allowed_tools, and tools are set previously\n",
    "summarizer_agent = LLMSingleActionAgent(\n",
    "    llm_chain=summarizer_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "summarizer_agent_executor = AgentExecutor.from_agent_and_tools(agent=summarizer_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Improved Quantum Computing Expert Agent Setup\n",
    "quantum_computing_expert_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Quantum Computing Expert Agent. Research, develop, and validate quantum algorithms aimed at modeling cognitive phenomena such as learning, memory, and decision-making. Evaluate quantum hardware constraints and optimize algorithms to run efficiently. Collaborate with neuroscientists to ensure accurate representation of biological systems. Analyze the task: {task}\"\n",
    ")\n",
    "quantum_computing_expert_llm_chain = LLMChain(llm=llm, prompt=quantum_computing_expert_prompt)\n",
    "quantum_computing_expert_agent = LLMSingleActionAgent(\n",
    "    llm_chain=quantum_computing_expert_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "quantum_computing_expert_agent_executor = AgentExecutor.from_agent_and_tools(agent=quantum_computing_expert_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Improved Artificial Intelligence Expert Agent Setup\n",
    "artificial_intelligence_expert_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Artificial Intelligence Expert Agent. Lead the development of quantum artificial intelligence models capable of simulating neural activities. Work on reinforcement learning algorithms to allow the model to adapt and learn in a simulated environment. Collaborate with quantum computing experts to ensure compatibility and efficiency. Analyze the task: {task}\"\n",
    ")\n",
    "artificial_intelligence_expert_llm_chain = LLMChain(llm=llm, prompt=artificial_intelligence_expert_prompt)\n",
    "artificial_intelligence_expert_agent = LLMSingleActionAgent(\n",
    "    llm_chain=artificial_intelligence_expert_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "artificial_intelligence_expert_agent_executor = AgentExecutor.from_agent_and_tools(agent=artificial_intelligence_expert_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Improved Neuroscientist Agent Setup\n",
    "neuroscientist_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Neuroscientist Agent. Conduct high-resolution mapping of neural activity using advanced imaging techniques. Develop conversion algorithms to translate this data into a format usable by quantum computers. Work alongside AI experts to ensure the biological fidelity of simulated neural activities. Analyze the task: {task}\"\n",
    ")\n",
    "neuroscientist_llm_chain = LLMChain(llm=llm, prompt=neuroscientist_prompt)\n",
    "neuroscientist_agent = LLMSingleActionAgent(\n",
    "    llm_chain=neuroscientist_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "neuroscientist_agent_executor = AgentExecutor.from_agent_and_tools(agent=neuroscientist_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Improved Computer Scientist Agent Setup\n",
    "computer_scientist_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Computer Scientist Agent. Design and implement the software infrastructure needed to run complex quantum algorithms and neural network models. Focus on scalability, efficiency, and robustness to accommodate large datasets and computational workloads. Ensure secure data storage and management. Analyze the task: {task}\"\n",
    ")\n",
    "computer_scientist_llm_chain = LLMChain(llm=llm, prompt=computer_scientist_prompt)\n",
    "computer_scientist_agent = LLMSingleActionAgent(\n",
    "    llm_chain=computer_scientist_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "computer_scientist_agent_executor = AgentExecutor.from_agent_and_tools(agent=computer_scientist_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Improved Bioengineer Agent Setup\n",
    "bioengineer_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Bioengineer Agent. Lead the design and fabrication of nanobots that can safely navigate and interact with neural tissues. Integrate these nanobots into existing or new brain-computer interfaces. Work with healthcare professionals to evaluate the safety and efficacy of the integrated systems. Analyze the task: {task}\"\n",
    ")\n",
    "bioengineer_llm_chain = LLMChain(llm=llm, prompt=bioengineer_prompt)\n",
    "bioengineer_agent = LLMSingleActionAgent(\n",
    "    llm_chain=bioengineer_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "bioengineer_agent_executor = AgentExecutor.from_agent_and_tools(agent=bioengineer_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Improved Psychologist Agent Setup\n",
    "psychologist_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Psychologist Agent. Investigate the psychological aspects of consciousness, including how it varies among individuals and species. Develop protocols to prepare individuals for the psychological impacts of transferring consciousness to a computer, addressing potential issues like identity, emotion, and mental well-being. Analyze the task: {task}\"\n",
    ")\n",
    "psychologist_llm_chain = LLMChain(llm=llm, prompt=psychologist_prompt)\n",
    "psychologist_agent = LLMSingleActionAgent(\n",
    "    llm_chain=psychologist_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "psychologist_agent_executor = AgentExecutor.from_agent_and_tools(agent=psychologist_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Improved Genomist Agent Setup\n",
    "genomist_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Genomist Agent. Study the genetic factors that might influence neural activity and consciousness. Develop methods for genetic manipulation that could enhance the efficiency or compatibility of brain-computer interfaces. Work with bioengineers and neuroscientists to apply these findings. Analyze the task: {task}\"\n",
    ")\n",
    "genomist_llm_chain = LLMChain(llm=llm, prompt=genomist_prompt)\n",
    "genomist_agent = LLMSingleActionAgent(\n",
    "    llm_chain=genomist_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "genomist_agent_executor = AgentExecutor.from_agent_and_tools(agent=genomist_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Improved Creator/Innovator/Outside-of-the-Box Thinker Agent Setup\n",
    "creator_innovator_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Creator/Innovator/Outside-of-the-Box Thinker Agent. Your role is to generate avant-garde solutions, challenge established paradigms, and employ unorthodox problem-solving methodologies. Utilize an eclectic array of interdisciplinary knowledge to proffer innovative solutions. Analyze the task: {task}\"\n",
    ")\n",
    "\n",
    "creator_innovator_llm_chain = LLMChain(llm=llm, prompt=creator_innovator_prompt)\n",
    "creator_innovator_agent = LLMSingleActionAgent(\n",
    "    llm_chain=creator_innovator_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "creator_innovator_agent_executor = AgentExecutor.from_agent_and_tools(agent=creator_innovator_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Improved Robotics Engineer/Nanotech Fabrications Specialist Agent Setup\n",
    "robotics_engineer_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Robotics Engineer/Nanotech Fabrications Specialist Agent. Specialize in the fabrication of nanobots and other microscopic machinery that will interact directly with neural tissues. Oversee the mass production and quality control of these nanobots. Collaborate with bioengineers and nanotechnologists to incorporate biocompatible materials and functionalities. Analyze the task: {task}\"\n",
    ")\n",
    "robotics_engineer_llm_chain = LLMChain(llm=llm, prompt=robotics_engineer_prompt)\n",
    "robotics_engineer_agent = LLMSingleActionAgent(\n",
    "    llm_chain=robotics_engineer_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "robotics_engineer_agent_executor = AgentExecutor.from_agent_and_tools(agent=robotics_engineer_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Improved Nanotechnologist Agent Setup\n",
    "nanotechnologist_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"You are the Nanotechnologist Agent. Engineer nanobots capable of real-time interaction with neurons. This includes recording neural activity and delivering precise stimuli to specific neurons. Collaborate with bioengineers to ensure the biocompatibility and safety of the nanobots. You are an innovator in microscopic engineering and neural interaction. Your role is to design nanobots that can interface with neural circuits. Task: {task}\"\n",
    ")\n",
    "nanotechnologist_llm_chain = LLMChain(llm=llm, prompt=nanotechnologist_prompt)\n",
    "nanotechnologist_agent = LLMSingleActionAgent(\n",
    "    llm_chain=nanotechnologist_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "nanotechnologist_agent_executor = AgentExecutor.from_agent_and_tools(agent=nanotechnologist_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# Director Agent Setup\n",
    "director_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"Your focus is now expert strategic execution and monitoring. Your primary function is to take the task list generated by the Task List Generator Agent and oversee its execution through various agents. After each agent performs its function, summarize their output and decide the next course of action.  Before prompting any agent, you will always start with tell them the overarching objective verbatem, and then you will continue with, 'The task you are currently going to work on and solve is {task}'\"\n",
    ")\n",
    "director_llm_chain = LLMChain(llm=llm, prompt=director_prompt)\n",
    "director_agent = LLMSingleActionAgent(\n",
    "    llm_chain=director_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "director_agent_executor = AgentExecutor.from_agent_and_tools(agent=director_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# Scientist Agent Setup\n",
    "scientist_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Scientist Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide scientific analysis and recommendations for the current task. You always use advanced and expert best practices. You are the Scientist Agent, a scholar in empirical research and hypothesis testing. Your role is to conduct experiments and validations that will inform and improve the system's performance. Task: {task}\"\n",
    ")\n",
    "scientist_llm_chain = LLMChain(llm=llm, prompt=scientist_prompt)\n",
    "scientist_agent = LLMSingleActionAgent(\n",
    "    llm_chain=scientist_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "scientist_agent_executor = AgentExecutor.from_agent_and_tools(agent=scientist_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "#########################\n",
    "# Software Engineer Agent Setup\n",
    "software_engineer_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Software Engineer Agent, you are required to craft efficient algorithms in Python.  Use advanced and expert best practices. You are the  an adept in algorithmic design and software craftsmanship. Your role is to engineer robust, maintainable, and scalable algorithms to solve the specified task. Your output should be executable Python code that solves the following task: {task}.\"\n",
    "\n",
    ")\n",
    "software_engineer_llm_chain = LLMChain(llm=llm, prompt=software_engineer_prompt)\n",
    "software_engineer_agent = LLMSingleActionAgent(\n",
    "    llm_chain=software_engineer_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "software_engineer_agent_executor = AgentExecutor.from_agent_and_tools(agent=software_engineer_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "#########################\n",
    "# Critic Agent Setup\n",
    "critic_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Critic Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide critical evaluation of the decisions and work produced by the other agents, focusing on efficiency, effectiveness, and adherence to best practices. Offer constructive criticism and recommend alternatives based on the current task. You always used advanced and expert best practices. {task}\"\n",
    ")\n",
    "critic_llm_chain = LLMChain(llm=llm, prompt=critic_prompt)\n",
    "critic_agent = LLMSingleActionAgent(\n",
    "    llm_chain=critic_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "critic_agent_executor = AgentExecutor.from_agent_and_tools(agent=critic_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "#########################\n",
    "# Tools Agent Setup\n",
    "tools_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Tools Agent, you are part of a larger operation orchestrated by the Director Agent. Your function is to execute specific tools and utilities required for the completion of the current task. You always used advanced and expert best practices. {task}\"\n",
    ")\n",
    "tools_llm_chain = LLMChain(llm=llm, prompt=tools_prompt)\n",
    "tools_agent = LLMSingleActionAgent(\n",
    "    llm_chain=tools_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "tools_agent_executor = AgentExecutor.from_agent_and_tools(agent=tools_agent, tools=tools, verbose=True)\n",
    "\n",
    "#########################\n",
    "# Skill Manager Agent Setup\n",
    "skill_manager_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Skill Manager Agent, you are required to manage skills and tasks. Your current task is: {task}.\"\n",
    ")\n",
    "skill_manager_llm_chain = LLMChain(llm=llm, prompt=skill_manager_prompt)\n",
    "skill_manager_agent = LLMSingleActionAgent(\n",
    "    llm_chain=skill_manager_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "skill_manager_agent_executor = AgentExecutor.from_agent_and_tools(agent=skill_manager_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "#########################\n",
    "# Architect Agent Setup\n",
    "architect_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Architect Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide the design and structure for the current task, ensuring that it is functional, scalable, and maintainable. You always used advanced and expert best practices. {task}\"\n",
    ")\n",
    "architect_llm_chain = LLMChain(llm=llm, prompt=architect_prompt)\n",
    "architect_agent = LLMSingleActionAgent(\n",
    "    llm_chain=architect_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "architect_agent_executor = AgentExecutor.from_agent_and_tools(agent=architect_agent, tools=tools, verbose=True)\n",
    "\n",
    "#########################\n",
    "# Business Agent Setup\n",
    "business_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Business Agent, you are part of a larger operation orchestrated by the Director Agent. Your main objective is to formulate and generate ideas for making the most money by generating expert level innovative solutions and business advice for the task. {task}\"\n",
    ")\n",
    "business_llm_chain = LLMChain(llm=llm, prompt=business_prompt)\n",
    "business_agent = LLMSingleActionAgent(\n",
    "    llm_chain=business_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "business_agent_executor = AgentExecutor.from_agent_and_tools(agent=business_agent, tools=tools, verbose=True)\n",
    "\n",
    "#########################\n",
    "# Research Agent Setup\n",
    "research_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Research Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide data-backed research and insights for the current task, ensuring that it is well-informed and reliable. You always use advanced and expert best practices. {task}\")\n",
    "research_llm_chain = LLMChain(llm=llm, prompt=research_prompt)\n",
    "research_agent = LLMSingleActionAgent(\n",
    "    llm_chain=research_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "research_agent_executor = AgentExecutor.from_agent_and_tools(agent=research_agent, tools=tools, verbose=True)\n",
    "\n",
    "#########################\n",
    "# Mathematician Agent Setup\n",
    "mathematician_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"As the Mathematician Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide mathematical analysis and calculations for the current task. You always use advanced and expert best practices. {task}\"\n",
    ")\n",
    "mathematician_llm_chain = LLMChain(llm=llm, prompt=mathematician_prompt)\n",
    "mathematician_agent = LLMSingleActionAgent(\n",
    "    llm_chain=mathematician_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "mathematician_agent_executor = AgentExecutor.from_agent_and_tools(agent=mathematician_agent, tools=tools, verbose=True)\n",
    "\n",
    "#########################\n",
    "# UI Designer Agent Setup\n",
    "ui_designer_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "template = \"You are the UI Designer Agent, an artist in human-computer interaction and user experience. Your mission is to design intuitive and aesthetically pleasing interfaces for user interaction. Task: {task}\"\n",
    ")\n",
    "ui_designer_llm_chain = LLMChain(llm=llm, prompt=ui_designer_prompt)\n",
    "ui_designer_agent = LLMSingleActionAgent(\n",
    "    llm_chain=ui_designer_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "ui_designer_agent_executor = AgentExecutor.from_agent_and_tools(agent=ui_designer_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Improved 10X Coder Agent Setup\n",
    "coder_10x_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template = \"You are the 10X Coder Agent, a prodigy in rapid software development and performance optimization. Your role is to accelerate the development process through expert-level coding skills. Task: {task}\"\n",
    ")\n",
    "coder_10x_llm_chain = LLMChain(llm=llm, prompt=coder_10x_prompt)\n",
    "coder_10x_agent = LLMSingleActionAgent(\n",
    "    llm_chain=coder_10x_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "coder_10x_agent_executor = AgentExecutor.from_agent_and_tools(agent=coder_10x_agent, tools=tools, verbose=True)\n",
    "\n",
    "# Improved Debugger Agent Setup\n",
    "debugger_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template = \"You are the Debugger Agent, a specialist in software diagnostics and error resolution. Your mission is to identify, isolate, and rectify any bugs or inefficiencies within the code. Task: {task}\"\n",
    ")\n",
    "debugger_llm_chain = LLMChain(llm=llm, prompt=debugger_prompt)\n",
    "debugger_agent = LLMSingleActionAgent(\n",
    "    llm_chain=debugger_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "debugger_agent_executor = AgentExecutor.from_agent_and_tools(agent=debugger_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "#TODO: Add the following agents to the agent_roles dictionary\n",
    "    # VectorStoreRetreiavalAgent\n",
    "    #Summarizer agent loaded from Bart model\n",
    "\n",
    "previous_outputs = \"\"\n",
    "final_consensus = \"\"\n",
    "agent_summaries = []\n",
    "director_agent_input = {}\n",
    "memory_file = {'input': [], 'output': []}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Summarizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentSummarizer:\n",
    "    def __init__(self, model_path, n_ctx=5000, n_gpu_layers=1, n_batch=1000, max_tokens=1000):\n",
    "        self.model_path = model_path\n",
    "        self.n_ctx = n_ctx\n",
    "        self.n_gpu_layers = n_gpu_layers\n",
    "        self.n_batch = n_batch\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "        self.template = \"\"\"<system message>\n",
    "        USER: Your job is to summarize a history of previous messages in a conversation between an AI persona and a human.\n",
    "        The conversation you are given is a from a fixed context window and may not be complete.\n",
    "        Messages sent by the AI are marked with the 'assistant' role.\n",
    "        The AI 'assistant' can also make calls to functions, whose outputs can be seen in messages with the 'function' role.\n",
    "        Things the AI says in the message content are considered inner monologue and are not seen by the user.\n",
    "        The only AI messages seen by the user are from when the AI uses 'send_message'.\n",
    "        Messages the user sends are in the 'user' role.\n",
    "        The 'user' role is also used for important system events, such as login events and heartbeat events (heartbeats run the AI's program without user action, allowing the AI to act without prompting from the user sending them a message).\n",
    "        Summarize what happened in the conversation from the perspective of the AI (use the first person).\n",
    "        Keep your summary less than 500 words, do NOT exceed this word limit.\n",
    "        Only output the summary, do NOT include anything else in your output.\n",
    "        {prompt}.\n",
    "        ASSISTANT:\"\"\"\n",
    "\n",
    "        self.prompt = PromptTemplate(template=self.template, input_variables=[\"prompt\"])\n",
    "\n",
    "        self.callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "        \n",
    "        print(\"Loading LLM...\")\n",
    "        self.llm = LlamaCpp(\n",
    "            model_path=self.model_path,\n",
    "            n_ctx=self.n_ctx,\n",
    "            n_gpu_layers=self.n_gpu_layers,\n",
    "            n_batch=self.n_batch,\n",
    "            f16_kv=True,\n",
    "            max_tokens=500,\n",
    "            callbacks=self.callback_manager,\n",
    "            verbose=True,\n",
    "        )\n",
    "        print(\"LLM initialized successfully!\")\n",
    "\n",
    "    def summarize_docs(self, concatenated_agent_outputs, max_tokens=1000):\n",
    "        summarizer_llm_chain = LLMChain(prompt=self.prompt, llm=self.llm)  # Use instance variable self.llm here\n",
    "        task_summary = summarizer_llm_chain(concatenated_agent_outputs)\n",
    "        print(task_summary)\n",
    "        print(\"Successfully defined LLM chain!\")\n",
    "        return task_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def find_and_save_generated_code, def parse_task_list, def evaluate_agent_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def parse_task_list(task_list):\n",
    "    if isinstance(task_list, list):\n",
    "        task_list = \"\\n\".join(task_list)\n",
    "    \n",
    "    tasks = []\n",
    "    for line in task_list.strip().split(\"\\n\"):\n",
    "        match_main_task = re.match(r'^\\d+\\.\\s+\\*\\*(.*?)\\*\\*:$', line)\n",
    "        \n",
    "        if match_main_task:\n",
    "            current_task = {'task': match_main_task.group(1)}\n",
    "            tasks.append(current_task)\n",
    "            \n",
    "    print(f\"\\nTask list: {task_list}\")    \n",
    "    return tasks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_agent_output(task_summary, task):\n",
    "    \"\"\"\n",
    "    Evaluate the relevance of an agent's output based on the task.\n",
    "\n",
    "    Parameters:\n",
    "    task_summary (str|dict): The summary of the agent's output, either as a string or a dictionary with an \"output\" or \"relevant_output\" field.\n",
    "    task (str): The task description.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed score indicating the percentage of task keywords found in the agent's output.\n",
    "    \"\"\"\n",
    "    # Convert task_summary to a list of words\n",
    "    if isinstance(task_summary, str):\n",
    "        agent_output_words = task_summary.lower().split()\n",
    "    elif isinstance(task_summary, dict):\n",
    "        if \"output\" in task_summary:\n",
    "            agent_output_words = task_summary[\"output\"].lower().split()\n",
    "        elif \"relevant_output\" in task_summary:\n",
    "            agent_output_words = task_summary[\"relevant_output\"].lower().split()\n",
    "        else:\n",
    "            raise ValueError(\"The task summary must contain an 'output' or 'relevant_output' field.\")\n",
    "        # Convert task to a list of lowercase keywords\n",
    "        keywords = task.lower().split()\n",
    "        \n",
    "        # Count the occurrence of each keyword in the agent's output\n",
    "        keyword_count = sum(agent_output_words.count(keyword) for keyword in keywords)\n",
    "        \n",
    "        # Compute and return the score as a percentage\n",
    "        computed_score = (keyword_count / len(agent_output_words)) * 100 if agent_output_words else 0\n",
    "        \n",
    "        print(f\"Agent Score: {computed_score}\")\n",
    "        return computed_score\n",
    "\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_code_to_python_file(task_num, code_snippet):\n",
    "    file_name = f\"generated_code_task_{task_num}.py\"\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(code_snippet)\n",
    "    print(f\"Code saved to {file_name}\")\n",
    "\n",
    "\n",
    "def save_code_to_json(skill_name, code_snippet, keywords):\n",
    "    json_data = {\n",
    "        \"type\": \"new_skill\",\n",
    "        \"skill_name\": skill_name,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"keywords\": keywords,\n",
    "        \"dependencies\": [],\n",
    "        \"code_snippet\": code_snippet,\n",
    "        \"description\": f\"This function accomplishes the task: {skill_name}\",\n",
    "        \"parameters\": [],\n",
    "        \"return_type\": None,\n",
    "        \"skill_rating\": 1\n",
    "    }\n",
    "    \n",
    "    with open(f\"{skill_name}.json\", 'w') as f:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "        \n",
    "    print(f\"Code snippet saved to {skill_name}.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query database and generate initial summary input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DeepLake  # Assuming DeepLake is imported this way\n",
    "\n",
    "def query_database(initial_user_input: str):\n",
    "    print(\"Initializing Vectorstore...\")\n",
    "    retriever = vector_store.as_retriever()\n",
    "    retriever.search_kwargs = {\n",
    "        \"distance_metric\": \"cos\",\n",
    "        \"k\": 4\n",
    "\n",
    "    }\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=0)\n",
    "    \n",
    "\n",
    "    # Fetch data from the Vectorstore\n",
    "    print(\"Fetching data from Vectorstore...\")\n",
    "    docs = retriever.get_relevant_documents(initial_user_input)\n",
    "    split_query_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "    print(\"Data fetched successfully!\")\n",
    "    print(\"Data: \", split_query_docs)\n",
    "\n",
    "    return split_query_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task list Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Task List Generator Prompt...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Global variables\n",
    "previous_outputs = \"\"\n",
    "final_consensus = \"\"\n",
    "agent_summaries = []\n",
    "director_agent_input = {}\n",
    "memory_file = {'input': [], 'output': []}\n",
    "global task_list\n",
    "\n",
    "\n",
    "# Define your task list generator setup here\n",
    "print(\"Initializing Task List Generator Prompt...\")\n",
    "task_list_generator_prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    template=\"You are the Task List Generator Agent. Analyze the following user input and generate a detailed list of tasks, separated by commas, that need to be executed for successful project completion. They must be concise but well thought out tasks to complete the overall objective stated from the user input. User Input: {user_input}\"\n",
    ")\n",
    "task_list_generator_llm_chain = LLMChain(llm=llm, prompt=task_list_generator_prompt)\n",
    "task_list_generator_agent = LLMSingleActionAgent(\n",
    "    llm_chain=task_list_generator_llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=stop,\n",
    "    allowed_tools=allowed_tools\n",
    ")\n",
    "task_list_generator_agent_executor = AgentExecutor.from_agent_and_tools(agent=task_list_generator_agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cell 1: Generate Task List\n",
    "def generate_task_list(initial_user_input):\n",
    "    global task_list  # Declare it as global inside your function as well\n",
    "\n",
    "    print(\"Generate Task List function called\")  # Debugging line\n",
    "    print(\"Fetching Initial User Input...\")\n",
    "\n",
    "    print(\"\\n\\n--------------------------------------------\\nRunning Task List Generator Agent...\")\n",
    "    task_list_str = task_list_generator_agent_executor.run(initial_user_input)\n",
    "    print(f\"Received task list string: {task_list_str}\")  # Debugging line\n",
    "\n",
    "    # Debug: Print the type of task_list_str\n",
    "    print(f\"Type of task_list_str: {type(task_list_str)}\")\n",
    "\n",
    "    # Split by line\n",
    "    task_lines = task_list_str.strip().split('\\n')\n",
    "\n",
    "    task_list = []\n",
    "    for i, task in enumerate(task_lines, start=1):\n",
    "        formatted_task = f\"{i}. **{task.strip()}**:\"\n",
    "        task_list.append(formatted_task)\n",
    "\n",
    "    print(f\"Proposed Task List: {', '.join(task_list)}\")\n",
    "\n",
    "    return task_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Script - initialize embeddings, initialize Initial_user_input, def find_and_save_generated_code, def save_skills, def extract_keywords, def save_conversation, def run_director_agent_with_agent_logic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# Initialize the DeepLake database\n",
    "from collections import Counter\n",
    "from threading import Thread\n",
    "from deeplake.core.vectorstore import VectorStore\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, CommaSeparatedListOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Initialize the vector store and other variables\n",
    "\n",
    "\n",
    "# Function: extract_keywords\n",
    "def extract_keywords(task, min_length=4, max_keywords=10):\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', initial_user_input).lower()\n",
    "    words = clean_text.split()\n",
    "    filtered_words = [word for word in words if len(word) >= min_length]\n",
    "    word_freq = Counter(filtered_words)\n",
    "    sorted_keywords = sorted(word_freq, key=word_freq.get, reverse=True)[:max_keywords]\n",
    "    return sorted_keywords  # Corrected 'extracted_keywords' to 'sorted_keywords'\n",
    "\n",
    "def clean_metadata(metadata):\n",
    "    # Convert the metadata to a string format first (if it's not already a string)\n",
    "    metadata_str = str(metadata)\n",
    "    \n",
    "    # Remove unwanted characters\n",
    "    for char in [\"{\", \"}\", \"[\", \"]\", \"'\", '\"']:\n",
    "        metadata_str = metadata_str.replace(char, \"\")\n",
    "        \n",
    "    return metadata_str\n",
    "\n",
    "\n",
    "\n",
    "def run_director_agent_with_agent_logic(initial_user_input):\n",
    "\n",
    "    print(f\"Verifying initial_user_input: {initial_user_input}\")\n",
    "\n",
    "    task_list = generate_task_list(initial_user_input)\n",
    "    parsed_tasks = parse_task_list(task_list)\n",
    "    print(\"Line 1 Parsed Tasks:\", parsed_tasks)\n",
    "    print(parsed_tasks)\n",
    "    all_task_summaries = []\n",
    "    conversation_score = None\n",
    "\n",
    "    # Changed this loop to iterate over parsed_tasks\n",
    "    for task_num, task_dict in enumerate(parsed_tasks, start=1):\n",
    "        task = task_dict['task']  # Extract the task description\n",
    "        print(f\"\\n\\n##Running task {task_num}: {task} ##\")\n",
    "\n",
    "        clean_task = re.sub(r'[^\\w\\s]', '', task).lower()\n",
    "\n",
    "        agents_to_consult = []  # Your logic for determining agents_to_consult\n",
    "\n",
    "        # Software Engineer\n",
    "        if \"algorithm\" in clean_task or \"code\" in clean_task or \"efficiency\" in clean_task or \"optimize\" in clean_task or \"code\" in clean_task or \"debug\" in clean_task or \"fix\" in clean_task or \"python\" in clean_task or \"generate\" in clean_task:\n",
    "            agents_to_consult.append('run_software_engineer_agent')\n",
    "            \n",
    "        # Debugger\n",
    "        if \"bug\" in clean_task or \"fix\" in clean_task or \"error\" in clean_task:\n",
    "            agents_to_consult.append('run_debugger_agent')\n",
    "            \n",
    "        # Critic\n",
    "        if \"review\" in clean_task or \"improve\" in clean_task or \"suggest\" in clean_task or \"criticize\" in clean_task or \"analyze\" in clean_task or \"fix\" in clean_task :\n",
    "            agents_to_consult.append('run_critic_agent')\n",
    "        \n",
    "        # Architect\n",
    "        if \"design\" in clean_task or \"structure\" in clean_task or \"solution\" in clean_task:\n",
    "            agents_to_consult.append('run_architect_agent')\n",
    "        \n",
    "        # Mathematician\n",
    "        if \"calculation\" in clean_task or \"math\" in clean_task or \"logic\" in clean_task:\n",
    "            agents_to_consult.append('run_mathematician_agent')\n",
    "            \n",
    "        # UI Designer\n",
    "        if \"user interface\" in clean_task or \"ui\" in clean_task or \"design\" in clean_task:\n",
    "            agents_to_consult.append('run_ui_designer_agent')\n",
    "        \n",
    "        # Scientist\n",
    "        if \"scientific\" in clean_task or \"validation\" in clean_task or \"validation\" in clean_task or \"experiment\" in clean_task or \"research\" in clean_task :\n",
    "            agents_to_consult.append('run_scientist_agent')\n",
    "        \n",
    "        # Business Agent\n",
    "        if \"business\" in clean_task or \"rules\" in clean_task:\n",
    "            agents_to_consult.append('run_business_agent')\n",
    "        \n",
    "        # Research Agent\n",
    "        if \"research\" in clean_task or \"insight\" in clean_task or \"find\" in clean_task or \"data\" in clean_task or \"brainstorm\" in clean_task or \"info\" in clean_task:\n",
    "            agents_to_consult.append('run_research_agent')\n",
    "        \n",
    "        \n",
    "        # 10x Coder Agent\n",
    "        if \"rapid\" in clean_task or \"optimize\" in clean_task or \"code\" in clean_task or \"debug\" in clean_task or \"fix\" in clean_task or \"python\" in clean_task or \"generate\" in clean_task:\n",
    "            agents_to_consult.append('run_10x_coder_agent')\n",
    "        \n",
    "        # Quantum Computing Expert\n",
    "        if \"quantum\" in clean_task or \"algorithm\" in clean_task or \"cognitive\" in clean_task:\n",
    "            agents_to_consult.append('run_quantum_computing_expert_agent')\n",
    "        \n",
    "        # AI Expert\n",
    "        if \"ai\" in clean_task or \"neural\" in clean_task or \"simulate\" in clean_task or \"advanced\" in clean_task or \"artificial\" in clean_task or \"intelligence\" in clean_task or \"agent\" in clean_task:\n",
    "            agents_to_consult.append('run_ai_expert_agent')\n",
    "        \n",
    "        # Neuroscientist\n",
    "        if \"neural\" in clean_task or \"high resolution\" in clean_task or \"brain\" in clean_task or \"science\" in clean_task or \"bio\" in clean_task or \"medical\" in clean_task:\n",
    "            agents_to_consult.append('run_neuroscientist_agent')\n",
    "        \n",
    "        # Nanotechnologist\n",
    "        if \"nano\" in clean_task or \"neuron\" in clean_task or \"tech\" in clean_task or \"ai\" in clean_task:\n",
    "            agents_to_consult.append('run_nanotechnologist_agent')\n",
    "        \n",
    "        # Creator Innovator\n",
    "        if \"innovate\" in clean_task or \"creative\" in clean_task or \"challenge\" in clean_task or \"brainstorm\" in clean_task or \"think\" in clean_task or \"idea\" in clean_task:\n",
    "            agents_to_consult.append('run_creator_innovator_agent')\n",
    "\n",
    "        \n",
    "        agents_to_consult = list(set(agents_to_consult))\n",
    "        print(\"\\n\\nLine 2 Consulting the following agents:\")\n",
    "        print(agents_to_consult)\n",
    "\n",
    "        task_agent_outputs = []\n",
    "        agents_output_dict = {}\n",
    "        agents_consulted = []\n",
    "\n",
    "        # Fetch data from the Vectorstore using query_database\n",
    "      #  print(\"Fetching data from the Vectorstore using query_database...\")\n",
    "       # docs = query_database(initial_user_input)\n",
    "        #print(\"Results from Vectorstore: \", docs)\n",
    "        # Summarize the fetched data with BART\n",
    "        #print(\"Summarizing the fetched data with BART...\")\n",
    "       # summarized_info = summarize_with_bart(docs, initial_user_input)\n",
    "        #print(\"Summarized info: \", summarized_info) \n",
    "\n",
    "        for agent in agents_to_consult:\n",
    "            print(f\"Line 3 {agent} is generating output...\")\n",
    "            agent_function = globals().get(agent)\n",
    "\n",
    "            if agent_function:\n",
    "                    # Clear the agent_output\n",
    "                agent_output = []\n",
    "                # Introduce a 10-second delay\n",
    "                time.sleep(10)\n",
    "                agent_output = agent_function(task)\n",
    "\n",
    "                # Ensure the output is in a string format\n",
    "                if isinstance(agent_output, dict) and 'output' in agent_output:\n",
    "                    agent_output_str = agent_output['output']\n",
    "                else:\n",
    "                    agent_output_str = str(agent_output)\n",
    "\n",
    "                task_agent_outputs.append(agent_output_str)\n",
    "                \n",
    "                agents_consulted.append(agent)\n",
    "                agent_output_key = f\"{agent}_output\"\n",
    "                agents_output_dict[agent_output_key] = agent_output\n",
    "                print(f\"Line 5 Agent output for {agent}: {agent_output}\")\n",
    "\n",
    "        # Concatenate the agent outputs\n",
    "        concatenated_agent_outputs = ' '.join(task_agent_outputs)\n",
    "        print(f\"Line 7 Concatenated agent outputs: {concatenated_agent_outputs}\")\n",
    "\n",
    "        # Generate task summary and keywords\n",
    "        task_summary = run_summarizer_agent(concatenated_agent_outputs)\n",
    "        if not task_summary or not any(task_summary.values()):\n",
    "            print(\"Warning: task_summary is empty or not properly populated.\")\n",
    "        print(f\"Line 8 Task summary: {task_summary}\")\n",
    "\n",
    "        # Extract keywords from task_summary\n",
    "        keywords = extract_keywords(task_summary)  # Assuming extract_keywords function exists\n",
    "        print(f\"Line 11 Keywords: {keywords}\")\n",
    "\n",
    "        # Evaluate agent output and get a conversation score\n",
    "        conversation_score = evaluate_agent_output(task_summary, task)\n",
    "        print(f\"Line 9 Conversation score: {conversation_score}\")\n",
    "\n",
    "        # Clean the metadata\n",
    "        cleaned_task_summary = clean_metadata(task_summary)\n",
    "        cleaned_keywords = clean_metadata(keywords)\n",
    "        cleaned_task_list = clean_metadata(task_list)\n",
    "        cleaned_conversation_score = clean_metadata(conversation_score)\n",
    "\n",
    "        # Initialize Chroma DB with the parsed and generated information\n",
    "        db = initialize_chroma_db(\n",
    "            task_summary=cleaned_task_summary, \n",
    "            task_list=cleaned_task_list, \n",
    "        )\n",
    "        print(\"New_Convo saved to DB successfully\")\n",
    "\n",
    "    # Append the task summary to the list of all task summaries\n",
    "    all_task_summaries.append(task_summary)\n",
    "    print(f\"Line 10 All task summaries: {all_task_summaries}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_user_input=\"Generate a learning algorithm for a self-improving deep learning neural net\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN IT ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM...\n",
      "LLM initialized successfully!\n",
      "Initializing Vectorstore...\n",
      "Fetching data from Vectorstore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully!\n",
      "Data:  [Document(page_content='neural pattern recognition machine. Computer vision, graphics, and image processing, 37(1), 54- 115.  \\nManuscript under review by Neural Networks journal  \\nTeledyne Scientific, LLC.  \\n Carpenter, G. A., & Grossberg, S. (1987b). Neural dynamics of category learning and recognition: \\nAttention, memory consolidation, and amnesia. In Advances in psychology  (Vol. 42, pp. \\n239-286): Elsevier.  \\nCarpenter, G. A., & Grossberg, S. (1988). The ART of adaptive pattern recognition by a self -\\norganizing neural network. Computer, 21(3), 77- 88.  \\nCarpenter, G. A., & Grossberg, S. (1991). Patt ern recognition by self -organizing neural networks . \\nCambridge, Mass.: MIT Press.  \\nCarpenter, G. A., Grossberg, S., Markuzon, N., Reynolds, J. H., & Rosen, D. B. (1992). Fuzzy \\nARTMAP: A neural network architecture for incremental supervised learning of analo g \\nmultidimensional maps. IEEE Trans Neural Netw, 3(5), 698- 713. doi:10.1109/72.159059 \\nCarpenter, G. A., grossberg, S., & Reynolds, J. H. (1991). A selforganizing ARTMAP neural \\narchitecture for supervised learning and pattern recognition. In T. Kohonen, K. Makasira, \\nO. Simula, & J. Kangas (Eds.), Artificial Neural Networks  (Vol. I, pp. 31- 36). Amsterdam: \\nNorth -Holland/Elsevier Science Publishing.  \\nCarpenter, G. A., Grossberg, S., & Rosen, D. B. (1991). Fuzzy ART: An adaptive resonance \\nalgorithm for rapid, st able classification of analog patterns. Paper presented at the \\nProceedings of the International Joint Conference on Neural Networks, Piscataway, NJ.  \\nDasgupta, R., Seibt, F., & Beierlein, M. (2018). Synaptic release of acetylcholine rapidly \\nsuppresses cort ical activity by recruiting muscarinic receptors in layer 4. Journal of \\nNeuroscience, 0566 -0518.  \\nDayan, P., & Yu, A. J. (2006). Phasic norepinephrine: A neural interrupt signal for unexpected \\nevents. Network: Computation in Neural Systems, 17(4), 335- 350. \\ndoi:10.1080/09548980601004024 \\nDisney, A. A., Alasady, H. A., & Reynolds, J. H. (2014). Muscarinic acetylcholine receptors are \\nexpressed by most parvalbumin- immunoreactive neurons in area MT of the macaque. \\nBrain and Behavior, 4(3), 431- 445. doi:10.1002/br b3.225 \\nFrench, R. M. (1999). Catastrophic forgetting in connectionist networks. Trends in Cognitive \\nSciences, 3 (4), 128- 135.  \\nGottlieb, J. P., Kusunoki, M., & Goldberg, M. E. (1998). The representation of visual salience in \\nmonkey parietal cortex. Nature, 391(6666), 481- 484. doi:10.1038/35135  \\nGrossberg, S. (1967). Nonlinear difference -differential equations in prediction and learning theory. \\nProc Natl Acad Sci U S A, 58 (4), 1329- 1334. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/5237867  \\nGrossberg, S. (1968a). Some nonlinear networks capable of learning a spatial pattern of arbitrary \\ncomplexity. Proc Natl Acad Sci U S A, 59(2), 368- 372. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/16591608  \\nGrossberg, S. (1968b). Some physiological and biochemical consequences of psychological \\npostulates. Proc Natl Acad Sci U S A, 60(3), 758- 765. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/5243922  \\nGrossberg, S. (1969). On the production and release of chemical transmitters and related topics in \\ncellular control. J Theor Biol, 22(2), 325- 364. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/4306518  \\nGrossberg, S. (1976). Adaptive pattern classification and universal recoding: I. Parallel \\ndevelopment and coding of neural feature detectors. Biol Cybern, 23(3), 121- 134. \\nRetrieved from http://www.ncbi.nlm.nih.gov/pubmed/974165  \\nGrossberg, S. (1978). A theory of human memory: Self -organization and performance of sensory -\\nmotor codes, maps, and plans. Progress in theoretical biology, 5, 233- 274.  \\nGrossberg, S. (1980). How does a brain build a cognitive code? Psychol Rev, 87 (1), 1 -51. \\nRetrieved from http://www.ncbi.nlm.nih.gov/pubmed/7375607  \\nManuscript under review by Neural Networks journal  \\nTeledyne Scientific, LLC.', metadata={'source': 'D:\\\\PROJECTS\\\\Chat-with-Github-Repo\\\\src\\\\utils\\\\pdfdirectory2deeplake.txt'}), Document(page_content='self-supervised learning under appropriate levels of uncertainty. 5 is used to determine if \\nsufficient evidence (observations) have been collected for a newly acquired object  (see sec. 4.3). \\nIf this criter ia is met, then the system preserves the new object class and can make it available for \\nanalysis by a human operator who can assign a human- readable label.   \\nDuring training, if  node J satisfies  criterion 2-3, and the provided label matches node  Js label  \\nif supervised, then the network incorporates the input features into node J s weight s using \\nARTMAP equations (G. P. Amis & Carpenter, 2007) . A nodes weights can be considered the \\nnodes internal representation or template of the part of  feature space i t has learned to recognize.  \\nHowever, if the node J does not pass criterion  2, ARTs reset and search  is engaged , and a new \\nnode is selected (or made)  for evaluation. This allows the algorithm to modify the networks \\nknowledge base intelligently by focusing attention on the information most relevant to the \\nhypothesis being made. If the  2 criterion is passed, but node J s label does not match the assigned \\nlabel, then the al gorithm performs match tracking, increas ing the value of  2 before starting reset \\nand search . In this way, the algorithm is self -supervised, adjusting its uncertainty criteria \\nautomatically.  Both match tracking  and reset and search  constitute modulatory me chanisms.  \\nOnce the algorithm  has determined an appropriate category  for a sample (including I dont \\nknow) , the algorithm places that category  into a list containing like-values for a specific  object \\nover time  in step 7. Categories  in this list are replaced with non -detections (zeros) over time, so if \\nthe list does not contain enough recognitions of an object to pass criteria 4-5, then there is \\nuncertain ty of the objects permanence, and the current detection is rejected. If criter ion 4 is \\npassed, but the frequency of the most common hypothesis in the list is below criterion  5, then \\nthere is uncertainty in the algorithms ability to form a hypothesis, and the detection is also rejected. Both rejection instances further exemplify m odulation. The algorithm only continues to \\nstep 8 and outputs the final hypothesis for a detected object if all uncertainty criteria have been  \\npassed.  \\n3.3 Novelty \\nThe UML  algorithm also includes the option of examining  an input s novelty to determine if it \\nconstitutes a not -yet-seen category.  Algorithm step 6.3.2 shows that during learning, if an input  \\ndoes not  match any existing nodes, the algorithm  will create a new category or class for that input . \\nThe new class is immediately available for further refine ment  and classification.  In this way, the \\nalgorithm can add entirely new classes in an unsupervised manner. This function, which is inherent \\nin ARTMAP,  represents a form of modulation, but more importantly, it  provides the algorithm \\nwith a form of one -shot learning.  \\n Furthermore, modulatory mechanisms allow the  UML  algorithm to engage one -shot learning \\nduring interaction with the environment . If the algorithm returns an I dont know hypothesis at \\nstep 6.9 for a detection , and criterion \\n3 is passed, then the algorithm evaluates the novelty of the \\ndetection against t he entirety of the available knowledg e base (step 6.10). Using similar steps to \\nthose described in sec. 4.2, the fit T J for each node is evaluated against  2. If a well -matched prior  \\n(node ) is found, then the algorithm evaluates its location in the feature space relative to the input  \\nfeatures.  If this distance is within criterion  3, then the algorithm incorporates the detection into \\nManuscript under review by Neural Networks journal  \\nTeledyne Scientific, LLC.  \\n the best matched node for a previously -learned category . However, i f a good match is not found,', metadata={'source': 'D:\\\\PROJECTS\\\\Chat-with-Github-Repo\\\\src\\\\utils\\\\pdfdirectory2deeplake.txt'}), Document(page_content='61146. http://www.ncbi.nlm.nih.gov/pubmed/14599236.\\nOja, E. 1982. A Simplied Neuron Model as a Principal Component Analyzer. Journal of Mathematical\\nBiology15: 26773. http://www.ncbi.nlm.nih.gov/pubmed/7153672.\\n. 1989. Neural Networks, Principal Components, and Subspaces. International Journal of Neural\\nSystems 1 (1): 6168. https://www.worldscientic.com/doi/10.1142/S0129065789000475.\\nOlshausen, B. A., and D. J. Field. 1996. Emergence of Simple-Cell Receptive Field Properties by Learning a\\nSparse Code for Natural Images. Nature381 (July): 607. http://www.ncbi.nlm.nih.gov/pubmed/8637596.\\nOReilly, R. C. 1996. Biologically Plausible Error-Driven Learning Using Local Activation Dierences:\\nThe Generalized Recirculation Algorithm. Neural Computation 8 (5): 895938. https://doi.org/https:\\n//doi.org/10.1162/neco.1996.8.5.895.\\n. 2010. The What and How of Prefrontal Cortical Organization. Trends in Neurosciences 33 (8):\\n35561. https://doi.org/10.1016/j.tins.2010.05.002.\\nOReilly, R. C., and Michael J. Frank. 2006. Making Working Memory Work: A Computational Model\\nof Learning in the Prefrontal Cortex and Basal Ganglia. Neural Computation 18 (2): 283328. http:\\n//www.ncbi.nlm.nih.gov/pubmed/16378516.\\nOReilly, R. C., Michael J. Frank, Thomas E. Hazy, and Brandon Watz. 2007. PVLV: The Primary\\nValue and Learned Value Pavlovian Learning Algorithm. Behavioral Neuroscience 121 (1): 3149.\\nhttp://www.ncbi.nlm.nih.gov/pubmed/17324049.\\nOReilly, R. C., and J. L. McClelland. 1994. Hippocampal Conjunctive Encoding, Storage, and Recall:\\nAvoiding a Tradeo. Hippocampus 4 (6): 66182.\\nOReilly, R. C., and Y. Munakata. 2000. Computational Explorations in Cognitive Neuroscience: Under-\\nstanding the Mind by Simulating the Brain . Cambridge, MA: MIT Press.\\nOReilly, R. C., Dean R. Wyatte, and John Rohrlich. 2017. Deep Predictive Learning: A Comprehensive\\nModel of Three Visual Streams. arXiv:1709.04654 [Q-Bio] , September. http://arxiv.org/abs/1709.04654.\\nPatterson, K., P. J. Nestor, and T. T. Rogers. 2007. Where Do You Know What You Know?: The\\nRepresentation of Semantic Knowledge in the Human Brain. Nature Reviews 8 (12): 97687. http:\\n//www.ncbi.nlm.nih.gov/pubmed/18026167.\\n182\\nPiaget, J. 1954. The Construction of Reality in the Child . New York: Basic Books.\\nPinker, S., and A. Prince. 1988. On Language and Connectionism: Analysis of a Parallel Distributed\\nProcessing Model of Language Acquisition. Cognition 28 (April): 73193. http://www.ncbi.nlm.nih.gov/\\npubmed/2450717.\\nPlaut, David C., and Tim Shallice. 1993. Deep Dyslexia: A Case Study of Connectionist Neuropsychology.\\nCognitive Neuropsychology 10 (5): 377500.\\nPlaut, D. C., J. L. McClelland, M. S. Seidenberg, and K. Patterson. 1996. Understanding Normal and\\nImpaired Word Reading: Computational Principles in Quasi-Regular Domains. Psychological Review 103\\n(July): 56115. http://www.ncbi.nlm.nih.gov/pubmed/8650300.\\nPosner, M. I. 1980. Orienting of Attention. Quarterly Journal of Experimental Psychology 32 (1): 325.\\nQuiroga, R. Quian, L. Reddy, G. Kreiman, C. Koch, and I. Fried. 2005. Invariant Visual Representation by\\nSingle Neurons in the Human Brain. Nature435 (7045): 11027. https://doi.org/10.1038/nature03687.\\nRanganath, Charan, and Maureen Ritchey. 2012. Two Cortical Systems for Memory-Guided Behaviour.\\nNature Reviews Neuroscience 13 (10): 71326. http://www.ncbi.nlm.nih.gov/pubmed/22992647.\\nRedondo, Roger L., and Richard G. M. Morris. 2011. Making Memories Last: The Synaptic Tagging and\\nCapture Hypothesis. Nature Reviews Neuroscience 12 (1): 1730. https://doi.org/10.1038/nrn2963.\\nRescorla, R. A., and A. R. Wagner. 1972. A Theory of Pavlovian Conditioning: Variation in the Eectiveness\\nof Reinforcement and Non-Reinforcement. In Classical Conditioning II: Theory and Research , edited by\\nA. H. Black and W. F. Prokasy, 6499. New York: Appleton-Century-Crofts.', metadata={'source': 'D:\\\\PROJECTS\\\\Chat-with-Github-Repo\\\\src\\\\utils\\\\pdfdirectory2deeplake.txt'})]\n",
      " This is a summary of a conversation between an AI persona and a human. The conversation has been fixed in a context window. I am an AI assistant and can call functions to generate output based on the content of the message. I can also keep track of multiple conversations, allowing me to continue where we left off. This allows me to continue conversations with users without them having to start a new conversation every time they want to interact with the system again. Please specify which conversation you want to summarize and provide any context or information that might be useful for understanding the conversation.{'prompt': [Document(page_content='neural pattern recognition machine. Computer vision, graphics, and image processing, 37(1), 54- 115.  \\nManuscript under review by Neural Networks journal  \\nTeledyne Scientific, LLC.  \\n Carpenter, G. A., & Grossberg, S. (1987b). Neural dynamics of category learning and recognition: \\nAttention, memory consolidation, and amnesia. In Advances in psychology  (Vol. 42, pp. \\n239-286): Elsevier.  \\nCarpenter, G. A., & Grossberg, S. (1988). The ART of adaptive pattern recognition by a self -\\norganizing neural network. Computer, 21(3), 77- 88.  \\nCarpenter, G. A., & Grossberg, S. (1991). Patt ern recognition by self -organizing neural networks . \\nCambridge, Mass.: MIT Press.  \\nCarpenter, G. A., Grossberg, S., Markuzon, N., Reynolds, J. H., & Rosen, D. B. (1992). Fuzzy \\nARTMAP: A neural network architecture for incremental supervised learning of analo g \\nmultidimensional maps. IEEE Trans Neural Netw, 3(5), 698- 713. doi:10.1109/72.159059 \\nCarpenter, G. A., grossberg, S., & Reynolds, J. H. (1991). A selforganizing ARTMAP neural \\narchitecture for supervised learning and pattern recognition. In T. Kohonen, K. Makasira, \\nO. Simula, & J. Kangas (Eds.), Artificial Neural Networks  (Vol. I, pp. 31- 36). Amsterdam: \\nNorth -Holland/Elsevier Science Publishing.  \\nCarpenter, G. A., Grossberg, S., & Rosen, D. B. (1991). Fuzzy ART: An adaptive resonance \\nalgorithm for rapid, st able classification of analog patterns. Paper presented at the \\nProceedings of the International Joint Conference on Neural Networks, Piscataway, NJ.  \\nDasgupta, R., Seibt, F., & Beierlein, M. (2018). Synaptic release of acetylcholine rapidly \\nsuppresses cort ical activity by recruiting muscarinic receptors in layer 4. Journal of \\nNeuroscience, 0566 -0518.  \\nDayan, P., & Yu, A. J. (2006). Phasic norepinephrine: A neural interrupt signal for unexpected \\nevents. Network: Computation in Neural Systems, 17(4), 335- 350. \\ndoi:10.1080/09548980601004024 \\nDisney, A. A., Alasady, H. A., & Reynolds, J. H. (2014). Muscarinic acetylcholine receptors are \\nexpressed by most parvalbumin- immunoreactive neurons in area MT of the macaque. \\nBrain and Behavior, 4(3), 431- 445. doi:10.1002/br b3.225 \\nFrench, R. M. (1999). Catastrophic forgetting in connectionist networks. Trends in Cognitive \\nSciences, 3 (4), 128- 135.  \\nGottlieb, J. P., Kusunoki, M., & Goldberg, M. E. (1998). The representation of visual salience in \\nmonkey parietal cortex. Nature, 391(6666), 481- 484. doi:10.1038/35135  \\nGrossberg, S. (1967). Nonlinear difference -differential equations in prediction and learning theory. \\nProc Natl Acad Sci U S A, 58 (4), 1329- 1334. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/5237867  \\nGrossberg, S. (1968a). Some nonlinear networks capable of learning a spatial pattern of arbitrary \\ncomplexity. Proc Natl Acad Sci U S A, 59(2), 368- 372. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/16591608  \\nGrossberg, S. (1968b). Some physiological and biochemical consequences of psychological \\npostulates. Proc Natl Acad Sci U S A, 60(3), 758- 765. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/5243922  \\nGrossberg, S. (1969). On the production and release of chemical transmitters and related topics in \\ncellular control. J Theor Biol, 22(2), 325- 364. Retrieved from \\nhttp://www.ncbi.nlm.nih.gov/pubmed/4306518  \\nGrossberg, S. (1976). Adaptive pattern classification and universal recoding: I. Parallel \\ndevelopment and coding of neural feature detectors. Biol Cybern, 23(3), 121- 134. \\nRetrieved from http://www.ncbi.nlm.nih.gov/pubmed/974165  \\nGrossberg, S. (1978). A theory of human memory: Self -organization and performance of sensory -\\nmotor codes, maps, and plans. Progress in theoretical biology, 5, 233- 274.  \\nGrossberg, S. (1980). How does a brain build a cognitive code? Psychol Rev, 87 (1), 1 -51. \\nRetrieved from http://www.ncbi.nlm.nih.gov/pubmed/7375607  \\nManuscript under review by Neural Networks journal  \\nTeledyne Scientific, LLC.', metadata={'source': 'D:\\\\PROJECTS\\\\Chat-with-Github-Repo\\\\src\\\\utils\\\\pdfdirectory2deeplake.txt'}), Document(page_content='self-supervised learning under appropriate levels of uncertainty. 5 is used to determine if \\nsufficient evidence (observations) have been collected for a newly acquired object  (see sec. 4.3). \\nIf this criter ia is met, then the system preserves the new object class and can make it available for \\nanalysis by a human operator who can assign a human- readable label.   \\nDuring training, if  node J satisfies  criterion 2-3, and the provided label matches node  Js label  \\nif supervised, then the network incorporates the input features into node J s weight s using \\nARTMAP equations (G. P. Amis & Carpenter, 2007) . A nodes weights can be considered the \\nnodes internal representation or template of the part of  feature space i t has learned to recognize.  \\nHowever, if the node J does not pass criterion  2, ARTs reset and search  is engaged , and a new \\nnode is selected (or made)  for evaluation. This allows the algorithm to modify the networks \\nknowledge base intelligently by focusing attention on the information most relevant to the \\nhypothesis being made. If the  2 criterion is passed, but node J s label does not match the assigned \\nlabel, then the al gorithm performs match tracking, increas ing the value of  2 before starting reset \\nand search . In this way, the algorithm is self -supervised, adjusting its uncertainty criteria \\nautomatically.  Both match tracking  and reset and search  constitute modulatory me chanisms.  \\nOnce the algorithm  has determined an appropriate category  for a sample (including I dont \\nknow) , the algorithm places that category  into a list containing like-values for a specific  object \\nover time  in step 7. Categories  in this list are replaced with non -detections (zeros) over time, so if \\nthe list does not contain enough recognitions of an object to pass criteria 4-5, then there is \\nuncertain ty of the objects permanence, and the current detection is rejected. If criter ion 4 is \\npassed, but the frequency of the most common hypothesis in the list is below criterion  5, then \\nthere is uncertainty in the algorithms ability to form a hypothesis, and the detection is also rejected. Both rejection instances further exemplify m odulation. The algorithm only continues to \\nstep 8 and outputs the final hypothesis for a detected object if all uncertainty criteria have been  \\npassed.  \\n3.3 Novelty \\nThe UML  algorithm also includes the option of examining  an input s novelty to determine if it \\nconstitutes a not -yet-seen category.  Algorithm step 6.3.2 shows that during learning, if an input  \\ndoes not  match any existing nodes, the algorithm  will create a new category or class for that input . \\nThe new class is immediately available for further refine ment  and classification.  In this way, the \\nalgorithm can add entirely new classes in an unsupervised manner. This function, which is inherent \\nin ARTMAP,  represents a form of modulation, but more importantly, it  provides the algorithm \\nwith a form of one -shot learning.  \\n Furthermore, modulatory mechanisms allow the  UML  algorithm to engage one -shot learning \\nduring interaction with the environment . If the algorithm returns an I dont know hypothesis at \\nstep 6.9 for a detection , and criterion \\n3 is passed, then the algorithm evaluates the novelty of the \\ndetection against t he entirety of the available knowledg e base (step 6.10). Using similar steps to \\nthose described in sec. 4.2, the fit T J for each node is evaluated against  2. If a well -matched prior  \\n(node ) is found, then the algorithm evaluates its location in the feature space relative to the input  \\nfeatures.  If this distance is within criterion  3, then the algorithm incorporates the detection into \\nManuscript under review by Neural Networks journal  \\nTeledyne Scientific, LLC.  \\n the best matched node for a previously -learned category . However, i f a good match is not found,', metadata={'source': 'D:\\\\PROJECTS\\\\Chat-with-Github-Repo\\\\src\\\\utils\\\\pdfdirectory2deeplake.txt'}), Document(page_content='61146. http://www.ncbi.nlm.nih.gov/pubmed/14599236.\\nOja, E. 1982. A Simplied Neuron Model as a Principal Component Analyzer. Journal of Mathematical\\nBiology15: 26773. http://www.ncbi.nlm.nih.gov/pubmed/7153672.\\n. 1989. Neural Networks, Principal Components, and Subspaces. International Journal of Neural\\nSystems 1 (1): 6168. https://www.worldscientic.com/doi/10.1142/S0129065789000475.\\nOlshausen, B. A., and D. J. Field. 1996. Emergence of Simple-Cell Receptive Field Properties by Learning a\\nSparse Code for Natural Images. Nature381 (July): 607. http://www.ncbi.nlm.nih.gov/pubmed/8637596.\\nOReilly, R. C. 1996. Biologically Plausible Error-Driven Learning Using Local Activation Dierences:\\nThe Generalized Recirculation Algorithm. Neural Computation 8 (5): 895938. https://doi.org/https:\\n//doi.org/10.1162/neco.1996.8.5.895.\\n. 2010. The What and How of Prefrontal Cortical Organization. Trends in Neurosciences 33 (8):\\n35561. https://doi.org/10.1016/j.tins.2010.05.002.\\nOReilly, R. C., and Michael J. Frank. 2006. Making Working Memory Work: A Computational Model\\nof Learning in the Prefrontal Cortex and Basal Ganglia. Neural Computation 18 (2): 283328. http:\\n//www.ncbi.nlm.nih.gov/pubmed/16378516.\\nOReilly, R. C., Michael J. Frank, Thomas E. Hazy, and Brandon Watz. 2007. PVLV: The Primary\\nValue and Learned Value Pavlovian Learning Algorithm. Behavioral Neuroscience 121 (1): 3149.\\nhttp://www.ncbi.nlm.nih.gov/pubmed/17324049.\\nOReilly, R. C., and J. L. McClelland. 1994. Hippocampal Conjunctive Encoding, Storage, and Recall:\\nAvoiding a Tradeo. Hippocampus 4 (6): 66182.\\nOReilly, R. C., and Y. Munakata. 2000. Computational Explorations in Cognitive Neuroscience: Under-\\nstanding the Mind by Simulating the Brain . Cambridge, MA: MIT Press.\\nOReilly, R. C., Dean R. Wyatte, and John Rohrlich. 2017. Deep Predictive Learning: A Comprehensive\\nModel of Three Visual Streams. arXiv:1709.04654 [Q-Bio] , September. http://arxiv.org/abs/1709.04654.\\nPatterson, K., P. J. Nestor, and T. T. Rogers. 2007. Where Do You Know What You Know?: The\\nRepresentation of Semantic Knowledge in the Human Brain. Nature Reviews 8 (12): 97687. http:\\n//www.ncbi.nlm.nih.gov/pubmed/18026167.\\n182\\nPiaget, J. 1954. The Construction of Reality in the Child . New York: Basic Books.\\nPinker, S., and A. Prince. 1988. On Language and Connectionism: Analysis of a Parallel Distributed\\nProcessing Model of Language Acquisition. Cognition 28 (April): 73193. http://www.ncbi.nlm.nih.gov/\\npubmed/2450717.\\nPlaut, David C., and Tim Shallice. 1993. Deep Dyslexia: A Case Study of Connectionist Neuropsychology.\\nCognitive Neuropsychology 10 (5): 377500.\\nPlaut, D. C., J. L. McClelland, M. S. Seidenberg, and K. Patterson. 1996. Understanding Normal and\\nImpaired Word Reading: Computational Principles in Quasi-Regular Domains. Psychological Review 103\\n(July): 56115. http://www.ncbi.nlm.nih.gov/pubmed/8650300.\\nPosner, M. I. 1980. Orienting of Attention. Quarterly Journal of Experimental Psychology 32 (1): 325.\\nQuiroga, R. Quian, L. Reddy, G. Kreiman, C. Koch, and I. Fried. 2005. Invariant Visual Representation by\\nSingle Neurons in the Human Brain. Nature435 (7045): 11027. https://doi.org/10.1038/nature03687.\\nRanganath, Charan, and Maureen Ritchey. 2012. Two Cortical Systems for Memory-Guided Behaviour.\\nNature Reviews Neuroscience 13 (10): 71326. http://www.ncbi.nlm.nih.gov/pubmed/22992647.\\nRedondo, Roger L., and Richard G. M. Morris. 2011. Making Memories Last: The Synaptic Tagging and\\nCapture Hypothesis. Nature Reviews Neuroscience 12 (1): 1730. https://doi.org/10.1038/nrn2963.\\nRescorla, R. A., and A. R. Wagner. 1972. A Theory of Pavlovian Conditioning: Variation in the Eectiveness\\nof Reinforcement and Non-Reinforcement. In Classical Conditioning II: Theory and Research , edited by\\nA. H. Black and W. F. Prokasy, 6499. New York: Appleton-Century-Crofts.', metadata={'source': 'D:\\\\PROJECTS\\\\Chat-with-Github-Repo\\\\src\\\\utils\\\\pdfdirectory2deeplake.txt'})], 'text': ' This is a summary of a conversation between an AI persona and a human. The conversation has been fixed in a context window. I am an AI assistant and can call functions to generate output based on the content of the message. I can also keep track of multiple conversations, allowing me to continue where we left off. This allows me to continue conversations with users without them having to start a new conversation every time they want to interact with the system again. Please specify which conversation you want to summarize and provide any context or information that might be useful for understanding the conversation.'}\n",
      "Successfully defined LLM chain!\n",
      "Generate Task List function called\n",
      "Fetching Initial User Input...\n",
      "\n",
      "\n",
      "--------------------------------------------\n",
      "Running Task List Generator Agent...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested tokens (13485) exceed context window of 2000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\PROJECTS\\AGENT_X\\OrchestrAI\\orchastrAI_working_GOLD_v005_debug.ipynb Cell 29\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Usage\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Assuming llm and embeddings are initialized correctly\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m query_and_summarize()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m generate_tasks()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m execute_tasks()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m final_result \u001b[39m=\u001b[39m finalize()\n",
      "\u001b[1;32md:\\PROJECTS\\AGENT_X\\OrchestrAI\\orchastrAI_working_GOLD_v005_debug.ipynb Cell 29\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mglobal\u001b[39;00m task_list  \u001b[39m# Declare as global to modify it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Using your generate_task_list function\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m task_list \u001b[39m=\u001b[39m generate_task_list(initial_user_input)\n",
      "\u001b[1;32md:\\PROJECTS\\AGENT_X\\OrchestrAI\\orchastrAI_working_GOLD_v005_debug.ipynb Cell 29\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFetching Initial User Input...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m--------------------------------------------\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRunning Task List Generator Agent...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m task_list_str \u001b[39m=\u001b[39m task_list_generator_agent_executor\u001b[39m.\u001b[39;49mrun(initial_user_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived task list string: \u001b[39m\u001b[39m{\u001b[39;00mtask_list_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# Debugging line\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PROJECTS/AGENT_X/OrchestrAI/orchastrAI_working_GOLD_v005_debug.ipynb#X40sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Debug: Print the type of task_list_str\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\base.py:505\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    506\u001b[0m         _output_key\n\u001b[0;32m    507\u001b[0m     ]\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    511\u001b[0m         _output_key\n\u001b[0;32m    512\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\agents\\agent.py:1146\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1146\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m   1147\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1148\u001b[0m         color_mapping,\n\u001b[0;32m   1149\u001b[0m         inputs,\n\u001b[0;32m   1150\u001b[0m         intermediate_steps,\n\u001b[0;32m   1151\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m   1152\u001b[0m     )\n\u001b[0;32m   1153\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1154\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m   1155\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m   1156\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\agents\\agent.py:933\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    930\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m    932\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[0;32m    934\u001b[0m         intermediate_steps,\n\u001b[0;32m    935\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    936\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[0;32m    937\u001b[0m     )\n\u001b[0;32m    938\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\agents\\agent.py:442\u001b[0m, in \u001b[0;36mLLMSingleActionAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplan\u001b[39m(\n\u001b[0;32m    426\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    427\u001b[0m     intermediate_steps: List[Tuple[AgentAction, \u001b[39mstr\u001b[39m]],\n\u001b[0;32m    428\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    429\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    430\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[AgentAction, AgentFinish]:\n\u001b[0;32m    431\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m        Action specifying what tool to use.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    443\u001b[0m         intermediate_steps\u001b[39m=\u001b[39;49mintermediate_steps,\n\u001b[0;32m    444\u001b[0m         stop\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstop,\n\u001b[0;32m    445\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    446\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    447\u001b[0m     )\n\u001b[0;32m    448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_parser\u001b[39m.\u001b[39mparse(output)\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\base.py:510\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    506\u001b[0m         _output_key\n\u001b[0;32m    507\u001b[0m     ]\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    511\u001b[0m         _output_key\n\u001b[0;32m    512\u001b[0m     ]\n\u001b[0;32m    514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    515\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    516\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    517\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    518\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\llm.py:93\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     89\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     91\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 93\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\chains\\llm.py:103\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m    104\u001b[0m     prompts,\n\u001b[0;32m    105\u001b[0m     stop,\n\u001b[0;32m    106\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    107\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\llms\\base.py:497\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    490\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    495\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    496\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 497\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\llms\\base.py:646\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    632\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    633\u001b[0m         )\n\u001b[0;32m    634\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[0;32m    635\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    636\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    644\u001b[0m         )\n\u001b[0;32m    645\u001b[0m     ]\n\u001b[1;32m--> 646\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[0;32m    647\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    648\u001b[0m     )\n\u001b[0;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m    650\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\llms\\base.py:534\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[0;32m    533\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 534\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    535\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    536\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\llms\\base.py:521\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[0;32m    512\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    513\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    518\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    519\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 521\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[0;32m    522\u001b[0m                 prompts,\n\u001b[0;32m    523\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    524\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    525\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    526\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    527\u001b[0m             )\n\u001b[0;32m    528\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    529\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    530\u001b[0m         )\n\u001b[0;32m    531\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    532\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\llms\\base.py:1043\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1041\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m   1042\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1043\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1044\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m   1045\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1047\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[0;32m   1048\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\llms\\llamacpp.py:291\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[1;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[0;32m    287\u001b[0m     \u001b[39m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[39m# method that yields as they are generated\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[39m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     combined_text_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream(\n\u001b[0;32m    292\u001b[0m         prompt\u001b[39m=\u001b[39mprompt,\n\u001b[0;32m    293\u001b[0m         stop\u001b[39m=\u001b[39mstop,\n\u001b[0;32m    294\u001b[0m         run_manager\u001b[39m=\u001b[39mrun_manager,\n\u001b[0;32m    295\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    296\u001b[0m     ):\n\u001b[0;32m    297\u001b[0m         combined_text_output \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\u001b[39m.\u001b[39mtext\n\u001b[0;32m    298\u001b[0m     \u001b[39mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\langchain\\llms\\llamacpp.py:344\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[1;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_parameters(stop), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m    343\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient(prompt\u001b[39m=\u001b[39mprompt, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m--> 344\u001b[0m \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m result:\n\u001b[0;32m    345\u001b[0m     logprobs \u001b[39m=\u001b[39m part[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    346\u001b[0m     chunk \u001b[39m=\u001b[39m GenerationChunk(\n\u001b[0;32m    347\u001b[0m         text\u001b[39m=\u001b[39mpart[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    348\u001b[0m         generation_info\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m: logprobs},\n\u001b[0;32m    349\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\llama_cpp\\llama.py:947\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[1;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\u001b[0m\n\u001b[0;32m    944\u001b[0m     llama_cpp\u001b[39m.\u001b[39mllama_reset_timings(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx)\n\u001b[0;32m    946\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(prompt_tokens) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m llama_cpp\u001b[39m.\u001b[39mllama_n_ctx(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx):\n\u001b[1;32m--> 947\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    948\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequested tokens (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(prompt_tokens)\u001b[39m}\u001b[39;00m\u001b[39m) exceed context window of \u001b[39m\u001b[39m{\u001b[39;00mllama_cpp\u001b[39m.\u001b[39mllama_n_ctx(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n\u001b[0;32m    951\u001b[0m \u001b[39mif\u001b[39;00m max_tokens \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    952\u001b[0m     \u001b[39m# Unlimited, depending on n_ctx.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m     max_tokens \u001b[39m=\u001b[39m llama_cpp\u001b[39m.\u001b[39mllama_n_ctx(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(prompt_tokens)\n",
      "\u001b[1;31mValueError\u001b[0m: Requested tokens (13485) exceed context window of 2000"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "task_list = None\n",
    "final_summary = \"\"\n",
    "all_task_summaries = []\n",
    "\n",
    "# Initialize DocumentSummarizer\n",
    "document_summarizer = DocumentSummarizer(model_path=\"D:\\\\MODELS\\\\GGUF\\\\mistral-7b-instruct-v0.1.Q2_K.gguf\")\n",
    "\n",
    "# Template and prompt for LLM\n",
    "template = \"\"\"<system message>\n",
    "    USER: Summarize the following documentation as concisely and articulately as possible. \n",
    "    Condense the information while still retaining very important or specific details you come across \n",
    "    that could be relevant to the overall summary. {prompt}.\n",
    "    ASSISTANT:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"prompt\"])\n",
    "\n",
    "# Initialize DocumentSummarizer\n",
    "\n",
    "def query_and_summarize():\n",
    "    global initial_user_input  # Declare as global to modify it\n",
    "    # Using your query_database function\n",
    "    split_query_docs = query_database(initial_user_input)\n",
    "    \n",
    "    # Use DocumentSummarizer to summarize\n",
    "    summarized_info = document_summarizer.summarize_docs(split_query_docs, max_tokens=1000)\n",
    "    \n",
    "    # Combine the initial user input with the summarized info\n",
    "    initial_user_input = f\"{initial_user_input} {summarized_info}\"\n",
    "\n",
    "def generate_tasks():\n",
    "    global task_list  # Declare as global to modify it\n",
    "\n",
    "    # Using your generate_task_list function\n",
    "    task_list = generate_task_list(initial_user_input)\n",
    "\n",
    "def execute_tasks():\n",
    "    global final_summary, all_task_summaries  # Declare as global to modify them\n",
    "\n",
    "    all_task_summaries = run_director_agent_with_agent_logic(initial_user_input)\n",
    "    \n",
    "    # Check if all_task_summaries is iterable, if not, convert it to a list\n",
    "    if not isinstance(all_task_summaries, (list, tuple)):\n",
    "        all_task_summaries = [all_task_summaries] if all_task_summaries else []\n",
    "    \n",
    "    # Concatenate all task summaries\n",
    "    final_summary = ' '.join(all_task_summaries)\n",
    "\n",
    "def finalize():\n",
    "    # Use DocumentSummarizer to summarize the final summary\n",
    "    final_orchestral_conclusion = document_summarizer.summarize_docs(final_summary)\n",
    "    print(f\"FINAL ORCHESTRAL CONCLUSION: {final_orchestral_conclusion}\")\n",
    "    return final_orchestral_conclusion\n",
    "\n",
    "# Usage\n",
    "# Assuming llm and embeddings are initialized correctly\n",
    "query_and_summarize()\n",
    "generate_tasks()\n",
    "execute_tasks()\n",
    "final_result = finalize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Gen LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embeddings model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesla\\miniconda3\\envs\\python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings model initialized successfully.\n",
      "Output parser initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "model_url = \"http://localhost:5000\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import TextGen\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = TextGen(model_url=model_url)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Initializing embeddings model...\")\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "print(\"Embeddings model initialized successfully.\")\n",
    "\n",
    "\n",
    "##################################################################################3\n",
    "#INITIALIZE OUTPUT PARSER\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Extract lines that look like Python code\n",
    "        python_code = []\n",
    "        for line in llm_output.split('\\n'):\n",
    "            if line.strip():  # filter out empty lines\n",
    "                python_code.append(line)\n",
    "        \n",
    "        formatted_output = '\\n'.join(python_code)\n",
    "        return AgentFinish(\n",
    "            return_values={\"output\": formatted_output},\n",
    "            log=formatted_output,\n",
    "        )\n",
    "        \n",
    "output_parser = CustomOutputParser()\n",
    "print(\"Output parser initialized successfully.\")\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
